{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV prediction for numus\n",
    "NumuCV = np.array([3.1e3,2.9e3])\n",
    "# systematic uncertainty, fractional\n",
    "SYST = 0.2\n",
    "NBINS = len(NumuCV)\n",
    "FluxFrac = 1e-1 # nue / numu flux fraction\n",
    "LEEFrac  = 0.5 # LEE / nue fraction\n",
    "# degree of correlation between numus and nues and between different energy bins in each channel\n",
    "CORR = 0.8 \n",
    "\n",
    "# generate a fluctuation of the numu expectation within stat / syst uncertainties\n",
    "def RandomNumu(Nbins):\n",
    "    universeWeight = np.random.normal(1,SYST)\n",
    "    Nuniverse = NumuCV * universeWeight\n",
    "    # using sqrt(N) error given high-stats regime\n",
    "    Nobs = np.random.normal(Nuniverse,np.sqrt(Nuniverse),Nbins)\n",
    "    return universeWeight,Nobs\n",
    "\n",
    "# build nue expectation given the numus\n",
    "def NueExpectation(numus):\n",
    "    return numus * FluxFrac\n",
    "\n",
    "# LEE expectation (LEEs only show up in 1st nue bin)\n",
    "def LEEExpectation(nues,F):\n",
    "    return np.array([nues[0] * F,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the H1 expectation under the LEE hypothesis\n",
    "# universe -> scaling of numus w.r.t. CV prediction\n",
    "# LEEFrac -> signal strength for LEE / nues\n",
    "# NBins: number of energy bins of each channel\n",
    "def H1(universe,LEEFrac,Nbins):\n",
    "    NnumuUniverse = universe * NumuCV\n",
    "    numuCV = np.ones(Nbins)\n",
    "    numuCV *= NnumuUniverse\n",
    "    nueCV = NueExpectation(numuCV) \n",
    "    LEECV = LEEExpectation(nueCV,LEEFrac)\n",
    "    return (np.array([numuCV, nueCV + LEECV])).flatten()\n",
    "\n",
    "# build the H0 expectation under the SM hypothesis\n",
    "# universe -> scaling of numus w.r.t. CV prediction\n",
    "# LEEFrac -> signal strength for LEE / nues\n",
    "# NBins: number of energy bins of each channel\n",
    "def H0(universe,Nbins):\n",
    "    NnumuUniverse = universe * NumuCV\n",
    "    numuCV = np.ones(Nbins)\n",
    "    numuCV *= NnumuUniverse\n",
    "    nueCV = NueExpectation(numuCV) \n",
    "    return (np.array([numuCV, nueCV])).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the covariance matrix given the expected bin-content EXP\n",
    "# EXP format, in e.g. 2-energy bins: [numu 1st bin, numu 2nd bin, nue 1st bin, nue 2nd bin]\n",
    "def BuildCovariance(EXP):\n",
    "    \n",
    "    V = SYST * EXP\n",
    "    \n",
    "    #print (V)\n",
    "    \n",
    "    COV_SYST = np.matmul((np.array([V])).T,np.array([V]))\n",
    "    \n",
    "    COV_STAT = np.zeros((len(EXP), len(EXP)), float)\n",
    "    np.fill_diagonal(COV_STAT,EXP) \n",
    "    \n",
    "    for n in range(len(EXP)):\n",
    "        for m in range(len(EXP)):\n",
    "            if (n == m): continue\n",
    "            COV_SYST[n][m] *= CORR\n",
    "\n",
    "    return COV_SYST + COV_STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the delta-chisq:\n",
    "# INV -> inverse of covariance matrix\n",
    "# H0_CV -> H0 \"mu\" expectation\n",
    "# H1_CV -> H1 \"mu\" expectation\n",
    "# data -> observation\n",
    "def deltachisq(INV,H0_CV,H1_CV,data):\n",
    "    diffH0 = (data-H0_CV)\n",
    "    diffH1 = (data-H1_CV)\n",
    "    chiH0 = diffH0.dot(INV).dot(diffH0.T)\n",
    "    chiH1 = diffH1.dot(INV).dot(diffH1.T)\n",
    "    return (chiH0-chiH1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a poisson fluctuated dataset\n",
    "# data -> array of expected bin contents\n",
    "def StatFluctuation(data):\n",
    "    ret = np.ones(len(data))\n",
    "    for i,v in enumerate(data):\n",
    "        #print ('v : ',v)\n",
    "        if (v < 0):\n",
    "            ret[i] = 0\n",
    "        else:\n",
    "            ret[i] = np.random.poisson(v)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToyH0(COV,INV,L,H0_CV,H1_CV,verbose=False):\n",
    "    NTOT = len(H0_CV)\n",
    "    # the next two lines generate the toy draw accounting for correlations\n",
    "    # see slide 11 of \n",
    "    # https://microboone-docdb.fnal.gov/cgi-bin/private/RetrieveFile?docid=30100\n",
    "    v = np.random.normal(0, 1, NTOT) # this replaces \"picking a universe\"\n",
    "    xtoy_H0 = H0_CV + v.dot(L)\n",
    "    # statistically fluctuate this draw\n",
    "    xtoy_H0 = StatFluctuation(xtoy_H0)\n",
    "    if (verbose):\n",
    "        print ('DATA  : ',xtoy_H0)\n",
    "        print ('MC H0 : ',H0_CV)\n",
    "        print ('MC H1 : ',H1_CV)\n",
    "    return deltachisq(INV,H0_CV,H1_CV,xtoy_H0)\n",
    "\n",
    "def ToyH1(COV,INV,L,H0_CV,H1_CV):\n",
    "    NTOT = len(H0_CV)\n",
    "    # the next two lines generate the toy draw accounting for correlations\n",
    "    # see slide 11 of \n",
    "    # https://microboone-docdb.fnal.gov/cgi-bin/private/RetrieveFile?docid=30100\n",
    "    v = np.random.normal(0, 1, NTOT) # this replaces \"picking a universe\"\n",
    "    xtoy_H1 = H1_CV + v.dot(L)\n",
    "    # statistically fluctuate this draw\n",
    "    xtoy_H1 = StatFluctuation(xtoy_H1)\n",
    "    return deltachisq(INV,H0_CV,H1_CV,xtoy_H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chisq_v is the distribution of chisq for H0\n",
    "# chisq_v_2 \"\" H1\n",
    "# return the median chisq (med)\n",
    "#and the chisq values encompassing 68% of the distribution (Nscan_low, Nscan_hih)\n",
    "# return also the p-values for the median (f_med) \n",
    "# and the +/- 1sigma (f_dn, f_up)\n",
    "def GetMedian1Sigma(chisq_v,chisq_v_2):\n",
    "    if (len(chisq_v) != len(chisq_v_2)):\n",
    "        print ('non-equal lengths! ERROR')\n",
    "        return -1\n",
    "    med = np.median(chisq_v)\n",
    "    Ntot = len(chisq_v)\n",
    "    lower = -np.inf\n",
    "    upper = np.inf\n",
    "    # find lower bound\n",
    "    Nscan_low = med\n",
    "    Frac_scanned = 0.\n",
    "    while (Frac_scanned < 0.34):\n",
    "        Nscan_low -= med/100.\n",
    "        Frac_scanned = len(np.where( (chisq_v < med) & (chisq_v  > Nscan_low))[0]) / float(Ntot) \n",
    "    # find upper bound\n",
    "    Nscan_hih = med\n",
    "    Frac_scanned = 0.\n",
    "    while (Frac_scanned < 0.34):\n",
    "        Nscan_hih += med/100.\n",
    "        Frac_scanned = len(np.where( (chisq_v > med) & (chisq_v  < Nscan_hih))[0]) / float(Ntot)\n",
    "    \n",
    "    # what fraction of events in chisq_v_2 are above the calculated values?\n",
    "    f_med = len(np.where(chisq_v_2 > med)[0]) / float(Ntot)\n",
    "    f_dn  = len(np.where(chisq_v_2 > Nscan_low)[0]) / float(Ntot)\n",
    "    f_up  = len(np.where(chisq_v_2 > Nscan_hih)[0]) / float(Ntot)\n",
    "    \n",
    "    return med,Nscan_low,Nscan_hih,f_med,f_dn,f_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the constrained COV matrix (see TN)\n",
    "def ConstrainCOV(COV,OBS):\n",
    "    # from:\n",
    "    # https://microboone-docdb.fnal.gov/cgi-bin/private/ShowDocument?docid=7583\n",
    "    # TN 255\n",
    "    INV = np.linalg.inv(COV)\n",
    "    Nbins = int(len(OBS)/2.)\n",
    "    NUMU_OBS = np.concatenate( (1./np.array(OBS[:Nbins]), np.zeros(Nbins)) )\n",
    "    BINV = INV + NUMU_OBS\n",
    "    B = np.linalg.inv(BINV)\n",
    "    return B,BINV\n",
    "  \n",
    "# return the inverse of matrix C (see TN)\n",
    "def ConstrainCV(COV,CV):\n",
    "    # from:\n",
    "    # https://microboone-docdb.fnal.gov/cgi-bin/private/ShowDocument?docid=7583\n",
    "    # TN 255\n",
    "    INV = np.linalg.inv(COV)\n",
    "    Nbins = int(len(CV)/2.)\n",
    "    NUMU_CV = np.concatenate( (1./np.array(CV[:Nbins]), np.zeros(Nbins)) )\n",
    "    print ('OBS : ',CV)\n",
    "    CINV = INV + NUMU_CV\n",
    "    return CINV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a matrix get the nue quadrant only\n",
    "def GetNueQuadrant(M):\n",
    "    M1 = np.array(M[NBINS:])\n",
    "    Nrow = len(M1)\n",
    "    C = np.array([M1[n][NBINS:] for n in range(Nrow)])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "# S -> signal scaling for the LEE w.r.t. nues\n",
    "# W_CV -> how much to scale the numus by for the CV expectation. e.g. 1 -> no additional scaling.\n",
    "# W_OBS -> how much to scale the numus for the observation. e.g. 0.8 -> observe 20% less numus then predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 0.5 # injected LEE signal strength\n",
    "W_CV = 1.0 # CV weight\n",
    "W_OBS = 0.8 # observed weight\n",
    "\n",
    "# Asimov dataset\n",
    "H1_CV = H1(W_CV,S,NBINS)\n",
    "H0_CV = H0(W_CV,NBINS)\n",
    "\n",
    "print ('Asimov H0 bin contents : ',H0_CV)\n",
    "\n",
    "# build the covariance matrix\n",
    "COV = BuildCovariance(H0_CV)\n",
    "INV = np.linalg.inv(COV)\n",
    "\n",
    "# get the nue only portion of the covariance matrix\n",
    "COV_nue = GetNueQuadrant(COV)\n",
    "INV_nue = GetNueQuadrant(INV)\n",
    "\n",
    "# measure numus\n",
    "H1_uni = H1(W_OBS,S,NBINS)\n",
    "H0_uni = H0(W_OBS,NBINS)\n",
    "H1_obs = StatFluctuation(H1_uni)\n",
    "print ('Observed bin contents (w/ LEE model) : ',H1_obs)\n",
    "\n",
    "# from:\n",
    "# https://microboone-docdb.fnal.gov/cgi-bin/private/ShowDocument?docid=7583\n",
    "# TN 255\n",
    "B,BINV = ConstrainCOV(COV,H1_obs)\n",
    "CINV = ConstrainCV(COV,H1_CV)\n",
    "\n",
    "# updated nue prediction based on constraint\n",
    "NfitH0 = (H0_CV.dot(CINV).dot(B))\n",
    "\n",
    "\n",
    "# grab only the nue portion of the fit and constrained COV matrix\n",
    "NfitH0_nue = np.array(NfitH0[NBINS:])\n",
    "B_nue = GetNueQuadrant(B)\n",
    "BINV_nue = GetNueQuadrant(BINV)\n",
    "print ('nue prediction after constraint (SM model) : ',NfitH0_nue)\n",
    "\n",
    "COVH1 = BuildCovariance(H1_CV)\n",
    "\n",
    "BH1,BINVH1 = ConstrainCOV(COVH1,H1_obs)\n",
    "CINVH1 = ConstrainCV(COVH1,H1_CV)\n",
    "\n",
    "NfitH1 = (H1_CV.dot(CINVH1).dot(BH1))\n",
    "\n",
    "NfitH0_nue = np.array(NfitH0[NBINS:])\n",
    "NfitH1_nue = np.array(NfitH1[NBINS:])\n",
    "\n",
    "# constrained diagonal errors on nues\n",
    "nue_err = np.sqrt(np.diag(B))[NBINS:]\n",
    "\n",
    "L = np.linalg.cholesky(COV)\n",
    "L2 = np.linalg.cholesky(B)\n",
    "\n",
    "L_nue = np.linalg.cholesky(COV_nue)\n",
    "L2_nue = np.linalg.cholesky(B_nue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_numu = []\n",
    "H0_CV_plot_numu = []\n",
    "\n",
    "xvals_nue = []\n",
    "xvals_nue_constr = []\n",
    "H0_CV_plot_nue = []\n",
    "H0_CV_plot_nue_constr = []\n",
    "\n",
    "H0_CV_plot_nue_constr_high = []\n",
    "H0_CV_plot_nue_constr_low = []\n",
    "\n",
    "\n",
    "for n in range(NBINS):\n",
    "    \n",
    "    xvals_numu.append(n-0.5)\n",
    "    xvals_numu.append(n+0.5)\n",
    "    H0_CV_plot_numu.append(H0_CV[n])\n",
    "    H0_CV_plot_numu.append(H0_CV[n])\n",
    "\n",
    "    xvals_nue.append(NBINS+n-0.5)\n",
    "    xvals_nue.append(NBINS+n+0.5)\n",
    "    H0_CV_plot_nue.append(H0_CV[NBINS+n])\n",
    "    H0_CV_plot_nue.append(H0_CV[NBINS+n])\n",
    "    \n",
    "    xvals_nue_constr.append(NBINS*2+n-0.5)\n",
    "    xvals_nue_constr.append(NBINS*2+n+0.5)\n",
    "    \n",
    "    H0_CV_plot_nue_constr.append(NfitH0[NBINS+n])\n",
    "    H0_CV_plot_nue_constr.append(NfitH0[NBINS+n])\n",
    "    \n",
    "    H0_CV_plot_nue_constr_high.append(NfitH0[NBINS+n]+nue_err[n])\n",
    "    H0_CV_plot_nue_constr_high.append(NfitH0[NBINS+n]+nue_err[n])    \n",
    "    H0_CV_plot_nue_constr_low.append(NfitH0[NBINS+n]-nue_err[n])\n",
    "    H0_CV_plot_nue_constr_low.append(NfitH0[NBINS+n]-nue_err[n])\n",
    "    \n",
    "    \n",
    "xvals_numu = np.array(xvals_numu) \n",
    "xvals_nue  = np.array(xvals_nue) \n",
    "H0_CV_plot_numu = np.array(H0_CV_plot_numu)\n",
    "H0_CV_plot_nue  = np.array(H0_CV_plot_nue)\n",
    "    \n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.plot(xvals_numu,H0_CV_plot_numu,'r-',lw=2)\n",
    "plt.plot(xvals_nue,H0_CV_plot_nue,'b-',lw=2)\n",
    "plt.plot(xvals_nue_constr,H0_CV_plot_nue_constr,'b-',lw=2)\n",
    "\n",
    "plt.fill_between(xvals_numu,\\\n",
    "                 H0_CV_plot_numu*(1-SYST),\\\n",
    "                 H0_CV_plot_numu*(1+SYST),\\\n",
    "                 color='r',alpha=0.2)\n",
    "\n",
    "Err_nue_unconstr = np.sqrt( (H0_CV_plot_nue * SYST)**2 + H0_CV_plot_nue )\n",
    "\n",
    "plt.fill_between(xvals_nue,\\\n",
    "                 H0_CV_plot_nue - Err_nue_unconstr,\\\n",
    "                 H0_CV_plot_nue + Err_nue_unconstr,\\\n",
    "                 color='b',alpha=0.2)\n",
    "\n",
    "plt.fill_between(xvals_nue_constr,\\\n",
    "                 H0_CV_plot_nue_constr_low,\\\n",
    "                 H0_CV_plot_nue_constr_high,\\\n",
    "                 color='b',alpha=0.2)\n",
    "\n",
    "plt.errorbar([0,1],H1_obs[:NBINS],yerr=np.sqrt(H1_obs[:NBINS]),fmt='o',color='k')\n",
    "plt.errorbar([4,5],H1_obs[NBINS:],yerr=np.sqrt(H1_obs[NBINS:]),fmt='o',color='k')\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xticks([0.5,2.5,4.5],labels=[r'$\\nu_{\\mu}$',r'$\\nu_e$',r'costr. $\\nu_e$'],\\\n",
    "           fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw toys to calculate delta-chisq distributions\n",
    "\n",
    "chisq_H0_Asimov_v = []\n",
    "chisq_H1_Asimov_v = []\n",
    "\n",
    "chisq_H0_Constr_v = []\n",
    "chisq_H1_Constr_v = []\n",
    "\n",
    "chisq_H0_Constr_full_v = []\n",
    "chisq_H1_Constr_full_v = []\n",
    "\n",
    "for n in range(30000):\n",
    "    \n",
    "    chisq_H0_Asimov_v.append(ToyH0(COV,INV,L,H0_CV,H1_CV))\n",
    "    chisq_H1_Asimov_v.append(ToyH1(COV,INV,L,H0_CV,H1_CV))\n",
    "    \n",
    "    # full cov\n",
    "    chisq_H1_Constr_full_v.append(ToyH1(B,BINV,L2,NfitH0,NfitH1))\n",
    "    chisq_H0_Constr_full_v.append(ToyH0(B,BINV,L2,NfitH0,NfitH1))\n",
    "    \n",
    "    # nue cov only\n",
    "    chisq_H1_Constr_v.append(ToyH1(B_nue,BINV_nue,L2_nue,NfitH0_nue,NfitH1_nue))\n",
    "    chisq_H0_Constr_v.append(ToyH0(B_nue,BINV_nue,L2_nue,NfitH0_nue,NfitH1_nue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS = np.linspace(-70,70,100)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.hist(chisq_H0_Asimov_v,bins=BINS,histtype='step',lw=2,color='r',linestyle='-',label='H0 1-step')\n",
    "plt.hist(chisq_H1_Asimov_v,bins=BINS,histtype='step',lw=2,color='b',linestyle='-',label='H1 1-step')\n",
    "\n",
    "plt.hist(chisq_H0_Constr_v,bins=BINS,histtype='step',lw=2,color='r',\\\n",
    "         linestyle='dotted',label=r'H0 2-step [$\\nu_e$ only $\\chi^2$]')\n",
    "plt.hist(chisq_H1_Constr_v,bins=BINS,histtype='step',lw=2,color='b',\\\n",
    "         linestyle='dotted',label=r'H1 2-step [$\\nu_e$ only $\\chi^2$]')\n",
    "\n",
    "med,m1sig,p1sig,pval,p1dn,p1up = GetMedian1Sigma(chisq_H1_Asimov_v,chisq_H0_Asimov_v)\n",
    "print ('p-value : %.04f in range [%.04f, %.04f]'%(pval,p1dn,p1up))\n",
    "plt.axvline(med,color='k',linestyle='-',label=r'$\\sigma$ %.2f'%(st.norm.ppf(1-pval)))\n",
    "\n",
    "med,m1sig,p1sig,pval,p1dn,p1up = GetMedian1Sigma(chisq_H1_Constr_v,chisq_H0_Constr_v)\n",
    "print ('p-value : %.04f in range [%.04f, %.04f]'%(pval,p1dn,p1up))\n",
    "plt.axvline(med,color='k',linestyle='dotted',label=r'$\\sigma$ %.2f'%(st.norm.ppf(1-pval)))\n",
    "\n",
    "plt.ylim(0., plt.ylim()[1]*1.6)\n",
    "plt.xlabel(r'$\\Delta\\chi^2$')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
