{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Run3?\n",
    "ISRUN3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = \"nuselection\"\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "BNB = \"\"\n",
    "EXT = \"\"\n",
    "NU  = \"\"\n",
    "NUE = \"\"\n",
    "DRT = \"\"\n",
    "NCPI0 = \"\"\n",
    "CCPI0 = \"\"\n",
    "CCNOPI = \"\"\n",
    "NCCPI = \"\"\n",
    "NCNOPI = \"\"\n",
    "\n",
    "if ISRUN3:\n",
    "    BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_beam_good_reco2_1e19'\n",
    "    EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G1_all_reco2'\n",
    "    NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "    NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "    DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "    NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "    CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "    CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "    CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "    NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "    NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "    \n",
    "else:\n",
    "    BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19'\n",
    "    EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C2_all_reco2'\n",
    "    #EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_C2_D1_D2_E1_E2_all_reco2' #Run1 + Run2\n",
    "    NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "    NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "    DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "    NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "    CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "    CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "mc = uproot.open(ls.ntuple_path+NU+\".root\")[fold][tree]\n",
    "ncpi0 = uproot.open(ls.ntuple_path+NCPI0+\".root\")[fold][tree]\n",
    "ccpi0 = uproot.open(ls.ntuple_path+CCPI0+\".root\")[fold][tree]\n",
    "ccnopi = uproot.open(ls.ntuple_path+CCNOPI+\".root\")[fold][tree]\n",
    "cccpi = uproot.open(ls.ntuple_path+CCCPI+\".root\")[fold][tree]\n",
    "ncnopi = uproot.open(ls.ntuple_path+NCNOPI+\".root\")[fold][tree]\n",
    "nccpi = uproot.open(ls.ntuple_path+NCCPI+\".root\")[fold][tree]\n",
    "nue = uproot.open(ls.ntuple_path+NUE+\".root\")[fold][tree]\n",
    "data = uproot.open(ls.ntuple_path+BNB+\".root\")[fold][tree]\n",
    "ext = uproot.open(ls.ntuple_path+EXT+\".root\")[fold][tree]\n",
    "dirt = uproot.open(ls.ntuple_path+DRT+\".root\")[fold][tree]\n",
    "lee = uproot.open(ls.ntuple_path+NUE+\".root\")[fold][tree]\n",
    "\n",
    "uproot_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "\n",
    "variables = [\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"shr_bkt_pdg\", \"selected\", \"nu_pdg\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\",\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"reco_nu_vtx_x\",\"reco_nu_vtx_y\",\"reco_nu_vtx_z\",\n",
    "    \"nu_e\",\"trk_bkt_pdg\",\"ccnc\",\n",
    "    \"trk_energy_muon\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    \"shr_llrpid_dedx\",\"shr_llrpid_dedx_U\",\"shr_llrpid_dedx_V\",\"shr_llrpid_dedx_Y\",\n",
    "    \"slnunhits\",\"slnhits\",\n",
    "    \"_opfilter_pe_beam\",\"flash_pe\",\n",
    "    \"nu_flashmatch_score\",\"trk_phi\",\n",
    "    \"trk_llr_pid_score_v\",\"trk_id\",\n",
    "    \"muon_e\",\"proton_e\",\"nproton\",\n",
    "    \"mc_pdg\", \"npi0\",\"interaction\",\"NeutrinoEnergy2\",\n",
    "    \"topological_score\",\"trk_len\",\"trk_theta\",\n",
    "    \"evnunhits\", \"nslice\", \"selected\",\n",
    "    \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\"]\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "SYSTEMATICS = []#  ['weightsFlux','weightsGenie']\n",
    "\n",
    "nue = nue.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "mc = mc.pandas.df(variables + WEIGHTS + MCFVARS  + SYSTEMATICS, flatten=False)\n",
    "ncpi0 = ncpi0.pandas.df(variables + WEIGHTS  + SYSTEMATICS, flatten=False)\n",
    "ccpi0 = ccpi0.pandas.df(variables + WEIGHTS  + SYSTEMATICS, flatten=False)\n",
    "ccnopi = ccnopi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "nccpi = nccpi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "ncnopi = ncnopi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "cccpi = cccpi.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "data = data.pandas.df(variables, flatten=False)\n",
    "ext = ext.pandas.df(variables, flatten=False)\n",
    "dirt = dirt.pandas.df(variables + WEIGHTS + SYSTEMATICS, flatten=False)\n",
    "lee = lee.pandas.df(variables + WEIGHTSLEE + SYSTEMATICS, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "# avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.2)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,nccpi,ncnopi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"topological_score\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"topological_score\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"topological_score\"])\n",
    "ext[\"extdata\"] = np.ones_like(ext[\"topological_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lee[\"is_signal\"] = lee[\"category\"] == 11\n",
    "data[\"is_signal\"] = data[\"category\"] == 11\n",
    "nue[\"is_signal\"] = nue[\"category\"] == 11\n",
    "mc[\"is_signal\"] = mc[\"category\"] == 11\n",
    "dirt[\"is_signal\"] = dirt[\"category\"] == 11\n",
    "ext[\"is_signal\"] = ext[\"category\"] == 11\n",
    "ncpi0[\"is_signal\"] = ncpi0[\"category\"] == 11\n",
    "ccpi0[\"is_signal\"] = ccpi0[\"category\"] == 11\n",
    "ccnopi[\"is_signal\"] = ccnopi[\"category\"] == 11\n",
    "nccpi[\"is_signal\"] = nccpi[\"category\"] == 11\n",
    "ncnopi[\"is_signal\"] = ncnopi[\"category\"] == 11\n",
    "\n",
    "lee.loc[lee['category'] == 1, 'category'] = 111\n",
    "lee.loc[lee['category'] == 10, 'category'] = 111\n",
    "lee.loc[lee['category'] == 11, 'category'] = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"cccpi\": cccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "scaling = 1\n",
    "\n",
    "SPLIT = 1.0\n",
    "\n",
    "if ISRUN3:\n",
    "    weights = {\n",
    "        \"mc\": 6.54e-3 * SPLIT * scaling,\n",
    "        \"nue\": 1.18e-4 * SPLIT * scaling,\n",
    "        \"ext\": 2.41e-2 * SPLIT * scaling,\n",
    "        \"dirt\": 2.66e-2 * scaling,\n",
    "        \"lee\": 1.18e-4 * SPLIT * scaling,\n",
    "        \"ncpi0\": 3.80e-3 * SPLIT * scaling,\n",
    "        \"ccpi0\": 1.34e-3 * SPLIT * scaling,\n",
    "        \"ccnopi\": 3.11e-03 * SPLIT * scaling,\n",
    "        \"nccpi\": 7.61e-04 * SPLIT * scaling,\n",
    "        \"ncnopi\": 1.74e-03 * SPLIT * scaling,\n",
    "        \"cccpi\": 1.63e-3 * SPLIT * scaling,\n",
    "    }\n",
    "    pot = 0.865e19*scaling\n",
    "else:\n",
    "    weights = {\n",
    "        \"mc\": 2.56e-2 * SPLIT * scaling,\n",
    "        \"nue\": 6.33e-4 * SPLIT * scaling,\n",
    "        \"ext\": 2.46e-1 * SPLIT * scaling,\n",
    "        \"dirt\": 1.04e-1 * scaling,\n",
    "        \"lee\": 6.33e-4 * SPLIT * scaling,\n",
    "        \"ncpi0\": 1.24e-2 * SPLIT * scaling,\n",
    "        \"ccpi0\": 9.58e-3 * SPLIT * scaling,\n",
    "        \"ccnopi\": 1.12e-02 * SPLIT * scaling,\n",
    "        \"nccpi\": 3.73e-03 * SPLIT * scaling,\n",
    "        \"ncnopi\": 1.08e-02 * SPLIT * scaling,\n",
    "        \"cccpi\": 5.51e-3 * SPLIT * scaling,\n",
    "    }\n",
    "    pot = 3.34e19*scaling\n",
    "    \n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fullweight'] = df['weightSplineTimesTune'] * POTweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muon selection\n",
    "QUERY = 'nslice == 1'\n",
    "#if ISRUN3: QUERY += ' and ((crtveto!=1) or (crthitpe < 100)) and (_closestNuCosmicDist > 20.)'\n",
    "#QUERY += ' and trk_len > 20'\n",
    "#QUERY += ' and topological_score > 0.06'\n",
    "#QUERY += ' and reco_nu_vtx_sce_x > 5 and reco_nu_vtx_sce_x < 251'\n",
    "#QUERY += ' and reco_nu_vtx_sce_y > -110 and reco_nu_vtx_sce_y < 110'\n",
    "#QUERY += ' and reco_nu_vtx_sce_z > 20 and reco_nu_vtx_sce_z < 986'\n",
    "#QUERY += ' and (_opfilter_pe_beam > 0 or bnbdata == 1 or extdata == 1)'\n",
    "#QUERY += ' and trkpid > 0.2'\n",
    "#QUERY += ' and reco_nu_vtx_x > 200.'\n",
    "\n",
    "print (QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue pre-selection\n",
    "QUERY = 'nslice == 1' # cut # 1\n",
    "#QUERY += ' and selected == 1'\n",
    "#QUERY += ' and topological_score > 0.06'\n",
    "#QUERY += ' and reco_nu_vtx_sce_x > 5 and reco_nu_vtx_sce_x < 251'\n",
    "#QUERY += ' and reco_nu_vtx_sce_y > -110 and reco_nu_vtx_sce_y < 110'\n",
    "#QUERY += ' and reco_nu_vtx_sce_z > 20 and reco_nu_vtx_sce_z < 986'\n",
    "#QUERY += ' and shr_llrpid_dedx_Y != 0'\n",
    "#QUERY += ' and n_tracks_contained > 0'\n",
    "#QUERY += 'trkpid '\n",
    "#if ISRUN3: QUERY += ' and (crtveto!=1) and (_closestNuCosmicDist > 20.)'\n",
    "#QUERY += ' and shr_energy_tot_cali > 0.07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VARIABLE, BINS, RANGE, XTIT = 'topological_score',30,(0,1),\"topological score\"\n",
    "\n",
    "fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=QUERY,\n",
    "    kind=\"event_category\",\n",
    "    #kind=\"interaction\",\n",
    "    #kind=\"sample\",\n",
    "    #kind='particle_pdg',\n",
    "    draw_sys=False,\n",
    "    stacksort=True,\n",
    "    title=XTIT,\n",
    "    #bins=asymm_bins,\n",
    "    bins=BINS,\n",
    "    range=RANGE,\n",
    ")\n",
    "\n",
    "#print(\"Profile likelihood: %.2f sigma @ 1.32e21 POT\" % my_plotter.significance_likelihood)\n",
    "#print(\"s/sqrt(b): %.2f sigma @ 1.32e21 POT\" % my_plotter.significance)\n",
    "\n",
    "#ax1.set_ylim(0,1200)\n",
    "#ax1.set_yscale(\"log\")\n",
    "#ax1.set_ylim(0,0.25)\n",
    "ax2.set_ylim(0.7,1.3)\n",
    "ax1.set_ylim(0.1,ax1.get_ylim()[1]*1.5)\n",
    "#fig.savefig(ls.plots_path+VARIABLE+\"_\"+date_time+\"_comonop_highx.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eff(df,var,query,acceptance,bin_edges,absval=False):\n",
    "    #print acceptance\n",
    "    bin_centers = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "    bins = []\n",
    "    bin_eff = []\n",
    "    bin_err = []\n",
    "    for i in range(len(bin_centers)):\n",
    "        binmin = bin_edges[i]\n",
    "        binmax = bin_edges[i+1]\n",
    "        bincut = '%s > %f and %s < %f'%(var,binmin,var,binmax)\n",
    "        if (absval == True):\n",
    "            bincut = '(%s > %f and %s < %f) or (%s > -%f and %s < -%f)'%(var,binmin,var,binmax,var,binmax,var,binmin)\n",
    "        if (acceptance != ''): bincut += ' and %s'%acceptance\n",
    "        #print bincut\n",
    "        df_tmp =  df.query(bincut) # cut on bin range for desired var.\n",
    "        df_sub = df_tmp.query(query) # apply constrain \n",
    "        if (df_tmp.shape[0] == 0): continue\n",
    "        eff = df_sub.shape[0] / float( df_tmp.shape[0] )\n",
    "        err = np.sqrt( eff*(1-eff)/df_tmp.shape[0] )\n",
    "        bin_eff.append( eff )\n",
    "        bin_err.append( err )\n",
    "        bins.append(bin_centers[i])\n",
    "        #print 'eff = %.02f @ bin = %.02f'%(eff,bin_centers[i])\n",
    "    return np.array(bins),np.array(bin_eff),np.array(bin_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1\n",
    "RMIN = 4000\n",
    "RMAX = 8000\n",
    "# Run 3\n",
    "#RMIN = 12000\n",
    "#RMAX = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "B = np.linspace(RMIN,RMAX,50)\n",
    "\n",
    "ACCEPTANCE = ''\n",
    "VAR = 'run' #'_pi0_e'\n",
    "\n",
    "for label,df in samples.items():\n",
    "    \n",
    "    if (label == \"lee\"):\n",
    "        continue\n",
    "\n",
    "    centers,vals,errs = Eff(df,VAR,QUERY,\"\",B)\n",
    "    #popt, pcov = curve_fit(CONST,centers,vals,sigma=errs,absolute_sigma=True)\n",
    "    plt.errorbar(centers,vals,yerr=errs,fmt='o-',label=r'%s'%(label))\n",
    "    #print 'intrinsic nue pass-rage : %.03f'%(popt[0])\n",
    "    #plt.axhline(popt[0],color='b')\n",
    "\n",
    "\n",
    "plt.xlabel(r'Run Number')\n",
    "plt.ylabel(r'SliceID')\n",
    "plt.grid()\n",
    "plt.legend(loc=1,fontsize=14,framealpha=0.5)\n",
    "#plt.yscale('log')\n",
    "plt.title(r'v08_00_00_26 Run1 Samples')\n",
    "#plt.legend(loc=7,fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
