{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import management\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # Autoreload all modules\n",
    "\n",
    "import importlib\n",
    "\n",
    "#standard imports\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "#custom modules\n",
    "import localSettings as ls\n",
    "import plotter\n",
    "import NUMUhelper as moreFunctions\n",
    "#import xgboost as xgb\n",
    "#import nue_booster \n",
    "\n",
    "#scientific imports\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.backends.backend_pdf\n",
    "import numpy as np\n",
    "#import awkward\n",
    "import math\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#put these throughout the code to reload if needed\n",
    "importlib.reload(ls)\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(moreFunctions)\n",
    "\n",
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use slimmed (preselected) files or naw?\n",
    "PRESEL = True\n",
    "MAKEPLOTS = False\n",
    "EXPORTTXTFILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RUN in [3]:\n",
    "    for FAKEDATASET in ['set1','set2','set3','set4','set5']:\n",
    "        print(\"starting {} {}...\".format(FAKEDATASET, RUN))\n",
    "        importlib.reload(ls)\n",
    "        if FAKEDATASET == 'set5': RUN = 1\n",
    "        tree = \"NeutrinoSelectionFilter\"\n",
    "        #####################################################\n",
    "        # Setting datapaths here instead of localsettings.py\n",
    "        # Makes it easier to mix and match data, IMO\n",
    "        # Should probably revert back to localsettings.py method in future\n",
    "\n",
    "        if PRESEL:\n",
    "            BNB_PATH = \"E:\\\\HEPPA\\\\Data\\\\PeLEE\\\\fake-data\\\\Slim\\\\\"\n",
    "            MC_PATH = \"E:\\\\HEPPA\\\\Data\\\\PeLEE\\\\0304_numupresel\\\\Run{}\\\\\".format(RUN)\n",
    "            APPEND = \"_numupresel\"\n",
    "        else:\n",
    "            BNB_PATH = \"E:\\\\HEPPA\\\\Data\\\\PeLEE\\\\fake-data\\\\Unslim\\\\\"\n",
    "            MC_PATH = \"E:\\\\HEPPA\\\\Data\\\\PeLEE\\\\0304\\\\Run{}\\\\\".format(RUN)\n",
    "            APPEND = ''\n",
    "\n",
    "\n",
    "        if RUN == 3:\n",
    "            USECRT = True\n",
    "            ############## SETUP DATASAMPLE PATHS ##############\n",
    "            BNB = 'prod_uboone_nu2020_fakedata_{}_run3b_reco2_v08_00_00_41_reco2'.format(FAKEDATASET)\n",
    "            ################ SETUP MC SAMPLE PATHS ###################\n",
    "            EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G1_all_reco2'+ls.APPEND\n",
    "            #EXT = 'ext'+ls.APPEND\n",
    "            NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'+ls.APPEND\n",
    "            DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'+ls.APPEND\n",
    "\n",
    "        elif RUN == 1:\n",
    "            USECRT = False\n",
    "            BNB = 'prod_uboone_nu2020_fakedata_{}_run1_reco2_v08_00_00_41_reco2'.format(FAKEDATASET)\n",
    "            EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_all_reco2'+ls.APPEND\n",
    "            #EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_all_reco2'+ls.APPEND #Run1 + Run2\n",
    "            NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'+ls.APPEND\n",
    "            DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'+ls.APPEND\n",
    "\n",
    "        mc = uproot.open(MC_PATH+NU+APPEND+\".root\")[ls.fold][tree]\n",
    "        ext = uproot.open(MC_PATH+EXT+APPEND+\".root\")[ls.fold][tree]\n",
    "        dirt = uproot.open(MC_PATH+DRT+APPEND+\".root\")[ls.fold][tree]\n",
    "\n",
    "        data = uproot.open(BNB_PATH+BNB+\".root\")[ls.fold][tree]\n",
    "\n",
    "        uproot_v = [mc,ext,data,dirt]\n",
    "\n",
    "        variables = [\n",
    "            #\"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"shr_theta\",\n",
    "            \"selected\", \"nu_pdg\",\n",
    "            \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "            \"shr_pfp_id_v\", \"category\",\"shr_theta\", 'theta',\n",
    "            \"topological_score\",\n",
    "            #\"shr_energy_tot\", \n",
    "            \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "            \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "            \"NeutrinoEnergy2\",\n",
    "            #\"run\",\"sub\",\"evt\",\n",
    "            \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "            \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "            #\"trk_pfp_id\",\n",
    "            \"trk_llr_pid_score_v\", # trk-PID score\n",
    "            \"trk_energy_proton_v\", # track energy under proton hyp\n",
    "            \"trk_energy_muon_v\", # track energy under muon hyp\n",
    "            \"trk_calo_energy_y_v\", # track calo energy\n",
    "            #\"pi0_energy2_Y\", # pi0 tagger variables\n",
    "            'true_nu_vtx_x','true_nu_vtx_y','true_nu_vtx_z',\n",
    "            \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "            \"nproton\", \"nmuon\",\n",
    "            \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "            \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "            \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "            \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \n",
    "            #\"trk_hits_tot\",\n",
    "            #\"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "            \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\"true_e_visible\",\n",
    "            \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "            \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "            \"trk_sce_start_x_v\",\"trk_sce_start_y_v\",\"trk_sce_start_z_v\",\n",
    "            \"trk_sce_end_x_v\",\"trk_sce_end_y_v\",\"trk_sce_end_z_v\",\n",
    "            \"trk_mcs_muon_mom_v\",\"trk_range_muon_mom_v\", \"trk_len_v\",\n",
    "            \"pfp_generation_v\",\"trk_distance_v\",\"trk_theta_v\",\"trk_phi_v\",\n",
    "            \"trk_energy_muon\",\"trk_energy_tot\",\"trk_energy\",\n",
    "            \"pfnhits\",\"pfnunhits\",\n",
    "        ]\n",
    "        #for numu selection\n",
    "        #the big G1 file is a picky eater\n",
    "        slimmed_variables = [\n",
    "            \"nslice\", \"selected\", \"nu_pdg\",\n",
    "            \"slpdg\", \"trk_score_v\",\"slclustfrac\",\n",
    "            #\"contained_fraction\",\n",
    "            \"backtracked_pdg\",\"category\",\n",
    "            \"topological_score\",\n",
    "            \"run\", \"sub\", \"evt\",\n",
    "            \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "            \"trk_sce_start_x_v\",\"trk_sce_start_y_v\",\"trk_sce_start_z_v\",\n",
    "            \"trk_sce_end_x_v\",\"trk_sce_end_y_v\",\"trk_sce_end_z_v\",\n",
    "            \"trk_mcs_muon_mom_v\",\"trk_range_muon_mom_v\", \"trk_len_v\",\n",
    "            'trk_llr_pid_score_v',\n",
    "            \"pfp_generation_v\",\"trk_distance_v\",\"trk_theta_v\",\"trk_phi_v\",\n",
    "            #\"trk_energy_muon\",\"trk_energy_tot\",\"trk_energy\",\n",
    "            'trk_energy_muon_v','trk_energy_proton_v',\n",
    "            \"pfnhits\",\"pfnunhits\",\n",
    "            'slnunhits','slnhits',\n",
    "            'NeutrinoEnergy2',\n",
    "        ]\n",
    "\n",
    "        if USECRT and RUN == 3:\n",
    "            variables.append(\"_closestNuCosmicDist\")\n",
    "            variables.append(\"crtveto\")\n",
    "            variables.append(\"crthitpe\")\n",
    "            variables.append(\"CosmicIP\")\n",
    "            slimmed_variables.append(\"_closestNuCosmicDist\")\n",
    "            slimmed_variables.append(\"crtveto\")\n",
    "            slimmed_variables.append(\"crthitpe\")\n",
    "            slimmed_variables.append(\"CosmicIP\")\n",
    "\n",
    "        #make the list unique\n",
    "        variables = list(set(variables))\n",
    "        BNB_variables = list(set(slimmed_variables))\n",
    "        print(BNB_variables)\n",
    "\n",
    "\n",
    "        WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\"]#\"leeweight\"\n",
    "        #WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\"]#, \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "        #MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "        #           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "        #           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "        MCVARS = [\n",
    "            \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "        ]\n",
    "        SYSTEMATICS = []# ['weightsFlux','weightsGenie']\n",
    "\n",
    "\n",
    "        data = data.pandas.df(BNB_variables, flatten=False)        \n",
    "        print(\"Data dataframe built...\")\n",
    "        mc = mc.pandas.df(variables + WEIGHTS + MCVARS, flatten=False)\n",
    "        print(\"MC dataframe built...\")\n",
    "        ext = ext.pandas.df(variables, flatten=False)\n",
    "        print(\"EXT dataframe built...\")\n",
    "        dirt = dirt.pandas.df(variables + WEIGHTS + MCVARS, flatten=False)\n",
    "        print(\"Dirt dataframe built...\")\n",
    "\n",
    "        #############################################################################################\n",
    "        #some scaling-related calculations\n",
    "\n",
    "        df_v = [mc,dirt]\n",
    "\n",
    "        for i,df in enumerate(df_v):\n",
    "            df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "            df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "            df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "            df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "            df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "            df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "            df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "            df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "            #df['weightSpline']  = df['weightSpline']  * df['weightTune']\n",
    "            #df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune'] * 0.7 #scale down pi0s\n",
    "        #\n",
    "        df_v = [mc,ext,data,dirt]\n",
    "\n",
    "        for i,df in enumerate(df_v):\n",
    "            df[\"slclnhits\"] = df[\"pfnhits\"].apply(lambda x: sum(x))\n",
    "            df[\"slclnunhits\"] = df[\"pfnunhits\"].apply(lambda x: sum(x))\n",
    "        #\n",
    "        #Ryan's calculated columns and various necessities\n",
    "        df_v = [mc,ext,data,dirt]\n",
    "\n",
    "        M_mu = 0.105 #GeV/c\n",
    "        M_p = 0.938 #GeV/c\n",
    "        M_n = 0.939 #GeV/c\n",
    "        B = 0.04 #binding energy of argon used in simulation\n",
    "        proton_pidscore = -0.2\n",
    "\n",
    "\n",
    "        for i,df in enumerate(df_v):\n",
    "            print(i)\n",
    "            #useful variables\n",
    "            df['trk_p_quality_v'] = (df['trk_mcs_muon_mom_v']-df['trk_range_muon_mom_v'])/df['trk_range_muon_mom_v']\n",
    "            df['trk_cos_theta_v'] = df['trk_theta_v'].apply(lambda x: np.cos(x))\n",
    "            df['trk_sin_theta_v'] = df['trk_theta_v'].apply(lambda x: np.sin(x))\n",
    "            df['trk_cos_phi_v'] = df['trk_phi_v'].apply(lambda x: np.cos(x))\n",
    "            df['trk_sin_phi_v'] = df['trk_phi_v'].apply(lambda x: np.sin(x))\n",
    "            df['trk_range_proton_mom_v'] = df['trk_energy_proton_v'].apply(lambda x: np.sqrt(2*M_p*x))\n",
    "            df['trk_range_muon_e_v'] = (df['trk_range_muon_mom_v']**2 + M_mu**2)**.5 # E\n",
    "            df['trk_range_muon_ke_v'] = df['trk_range_muon_e_v'] - M_mu #KE\n",
    "            df['trk_energy_tot'] = df[\"trk_energy_proton_v\"].apply(lambda x: sum(x)) #is missing from G1 sample\n",
    "\n",
    "            df['reco_nu_e_range_v'] = df[\"trk_range_muon_e_v\"] + (df[\"trk_energy_tot\"] - df[\"trk_energy_proton_v\"])     \n",
    "            #protons have trk_score cut and llr_pid_score cut\n",
    "            proton_mask = df['trk_score_v'].apply(lambda x: x>0.5) * df['trk_llr_pid_score_v'].apply(lambda x: x<proton_pidscore)\n",
    "            df['reco_nproton'] = (df['trk_llr_pid_score_v']*proton_mask).apply(lambda x: len(x[x!=False]))\n",
    "            df['reco_ntrack'] = df['trk_score_v'].apply(lambda x: len(x))\n",
    "            # break momentum vector apart\n",
    "            df['trk_dx_v'] = df['trk_sin_theta_v']*df['trk_cos_phi_v']\n",
    "            df['trk_dy_v'] = df['trk_sin_theta_v']*df['trk_sin_phi_v']\n",
    "            df['trk_dz_v'] = df['trk_cos_theta_v']\n",
    "\n",
    "            #definitions related to neutrino energy\n",
    "            #df['nu_e_QE_proton_v'] = 0.5 * (2 * (M_n - B) * df['trk_energy_proton_v'] - ((M_n - B)**2 + M_p**2 - M_mu**2)) / ((M_n-B)-df['trk_energy_proton_v']+np.sqrt(df['trk_energy_proton_v']**2-M_p**2)*df['trk_cos_v'])\n",
    "            #df['nu_e_QE_muon_v'] = 0.5 * (2 * (M_n - B) * df['trk_energy_muon_v'] - ((M_n - B)**2 + M_p**2 - M_mu**2)) / ((M_n-B)-df['trk_energy_muon_v']+np.sqrt(df['trk_energy_muon_v']**2-M_p**2)*df['trk_cos_v'])\n",
    "            #df['2body_E_cons_v'] = np.sqrt((df['reco_nu_e_range_v']-df['nu_e_QE_proton_v'])**2+(df['reco_nu_e_range_v']-df['nu_e_QE_muon_v'])**2+(df['nu_e_QE_muon_v']-df['nu_e_QE_proton_v'])**2)\n",
    "\n",
    "\n",
    "            #just MC stuff (truth level)\n",
    "            if i in [0,3]:\n",
    "                df['backtracked_pdg_v'] = df['backtracked_pdg']\n",
    "\n",
    "            #This information is useful for applying corrections and such\n",
    "            if i == 2 or i == 4: df['bnbdata'] = 1\n",
    "            else: df['bnbdata'] = 0\n",
    "            if i == 1: df['extdata'] = 1\n",
    "            else: df['extdata'] = 0\n",
    "            if i in [1,2,4]:\n",
    "                #column needs to exist, even if not cut on \n",
    "                df['_opfilter_pe_beam'] = 999\n",
    "                df['_opfilter_pe_veto'] = -999\n",
    "            if i not in [0,3] and USECRT and RUN == 3:\n",
    "                #only apply to data and ext\n",
    "                df.loc[(df['run'] > 16300),'crthitpe'] = df['crthitpe']*1.09 #hitpe correction\n",
    "        # add back the cosmic category\n",
    "        # and calculate Nproton multiplicity if you so desire\n",
    "        NPROTON_CAT = True\n",
    "        df = mc\n",
    "        df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4\n",
    "        if NPROTON_CAT:\n",
    "            df.loc[(df['category']==2)&(df['nproton']==0), 'category'] = 22\n",
    "            df.loc[(df['category']==2)&(df['nproton']==1), 'category'] = 23\n",
    "            df.loc[(df['category']==2)&(df['nproton']==2), 'category'] = 24\n",
    "            df.loc[(df['category']==2)&(df['nproton']>=3), 'category'] = 25\n",
    "\n",
    "        nue = mc.query('nu_pdg == 12 or nu_pdg == -12')\n",
    "        mc  = mc.query('nu_pdg == 14 or nu_pdg == -14')\n",
    "\n",
    "        #####################################################################################\n",
    "        #put the samples in a way that's convient to acces later\n",
    "        scaling = 1\n",
    "        bnb_type = 'FD' + FAKEDATASET[-1]   \n",
    "\n",
    "        weights, pot = moreFunctions.get_scaling(RUN, bnb_type, scaling)\n",
    "\n",
    "        samples = {\"mc\": mc,\"nue\": nue,\"data\": data,\"ext\": ext,\"dirt\": dirt}\n",
    "\n",
    "        # ensure presel consistnecy\n",
    "        if PRESEL:\n",
    "            for sample in samples:\n",
    "                if sample in ['mc','nue','dirt']: OPFIL = True\n",
    "                else: OPFIL = False\n",
    "                presel,_ = moreFunctions.get_NUMU_sel(USECRT, opfilter=OPFIL)\n",
    "                samples[sample] = samples[sample].query(presel)#.dropna()\n",
    "\n",
    "        my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "\n",
    "        print(\"weights:\")\n",
    "        for weight in weights:\n",
    "            print(\"{}: {}\".format(weight,weights[weight]))\n",
    "        print(\"POT: {}\".format(pot))\n",
    "\n",
    "        ###############################################################\n",
    "        ## APPLY SELECTIONS\n",
    "        fullsel_samples = {}\n",
    "        presel_samples = {}\n",
    "        query,_ = moreFunctions.get_NUMU_sel(USECRT)\n",
    "\n",
    "        for sample in samples:\n",
    "            presel_samples[sample] = samples[sample].query(query)\n",
    "            if \"presel\" in ls.SAMPLE:\n",
    "                samples[sample] = presel_samples[sample]\n",
    "\n",
    "        for sample in samples:\n",
    "            print(\"{}: {}\".format(sample, moreFunctions.get_current_time(\"%H:%M:%S\")))\n",
    "            fullsel_samples[sample] = moreFunctions.apply_muon_fullsel(presel_samples[sample], sample, USECRT, False)\n",
    "            fullsel_samples[sample]['reco_ntrack'] = presel_samples[sample].loc[fullsel_samples[sample].index]['reco_ntrack']\n",
    "\n",
    "            \n",
    "        ###############################################################\n",
    "        ## Export TXT files for SBNFit \n",
    "        if EXPORTTXTFILES:\n",
    "            # need to compress these vector-valued columns of interest to scalar-valued ones\n",
    "            variables = ['trk_theta_v','trk_range_muon_e_v','reco_nu_e_range_v']\n",
    "            for sample in fullsel_samples.keys():\n",
    "                df = fullsel_samples[sample]\n",
    "                trk_lens = df['trk_len_v']\n",
    "                longest_mask = trk_lens.apply(lambda x: x == x[list(x).index(max(x))]) #identify longest\n",
    "                for variable in variables:\n",
    "                    VAR = df[variable]\n",
    "                    VAR = VAR.apply(lambda x: x[~np.isnan(x)]) #clean up nan vals\n",
    "                    VAR = VAR[VAR.apply(lambda x: len(x) > 0)]\n",
    "                    VAR = (VAR*longest_mask).apply(lambda x: x[x != False]) #apply longest mask\n",
    "                    if len(VAR.iloc[0]) == 1:\n",
    "                        VAR = VAR.apply(lambda x: x[0])\n",
    "                        #apply this new column\n",
    "                        new_variable = variable[:-2]\n",
    "                        df[new_variable] = VAR\n",
    "                    else:\n",
    "                        print('something is wrong...')\n",
    "                        print(VAR)\n",
    "            # just spit out some diagnostics    \n",
    "            binedges = np.linspace(0.15,1.55,15)\n",
    "            print(\"binedges:{}\".format(binedges))\n",
    "\n",
    "            for s,sample in enumerate(fullsel_samples):\n",
    "                print(sample)\n",
    "                df = fullsel_samples[sample].copy()\n",
    "                binvals,_ = np.histogram(df['reco_nu_e_range'], bins=binedges)\n",
    "                print(binvals,\" -> \",sum(binvals))\n",
    "            #do the txt file exportation\n",
    "            SAVEPATH = \"passing_events\\\\fake-data-{}\\\\\".format(FAKEDATASET[-1])\n",
    "            if not os.path.exists(SAVEPATH):\n",
    "                os.makedirs(SAVEPATH)\n",
    "\n",
    "            for sample in ['mc','data']:\n",
    "                print(sample)\n",
    "                f_out = open(SAVEPATH+\"{}_Passingevents_{}_{}.txt\".format(sample,FAKEDATASET,date_time),'w')\n",
    "                df = fullsel_samples[sample].query('reco_nu_e_range >= 0')\n",
    "\n",
    "                print ('file %s_final has %i selected entries'%(sample,df.shape[0]))\n",
    "                f_out.write('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n'%('run','sub','evt','angle','Emuon','Erange'))\n",
    "                for i,row in df.iterrows():\n",
    "                    run = row['run']\n",
    "                    sub = row['sub']\n",
    "                    evt = row['evt']\n",
    "                    angle = row['trk_theta']\n",
    "                    Emuon = row['trk_range_muon_e']\n",
    "                    Erange = row['reco_nu_e_range']\n",
    "                    f_out.write('%i\\t%i\\t%i\\t%.4f\\t%.4f\\t%.4f\\n'%(run,sub,evt,angle,Emuon,Erange))\n",
    "                f_out.close()\n",
    "        \n",
    "        ############################################################### \n",
    "        ## MAKE ALL THE PLOTS\n",
    "        if MAKEPLOTS:\n",
    "            VECS = [\n",
    "                'reco_nu_e_range_v', 'trk_range_muon_e_v',\n",
    "                'trk_len_v','trk_cos_theta_v'\n",
    "            ]\n",
    "            for sample in fullsel_samples:\n",
    "                for vec in VECS:\n",
    "                    fullsel_samples[sample][vec[:-2]] = fullsel_samples[sample][vec].apply(lambda x: x[0])\n",
    "            #####################################################################################################\n",
    "            #active volume\n",
    "            AVx = [-1.55,254.8]\n",
    "            AVy = [-115.53, 117.47]\n",
    "            AVz = [0.1, 1036.9]\n",
    "\n",
    "\n",
    "            for (plot_type,tag) in zip(['presel input noCRT', 'muon input', 'fullselKinematics'],['samples','presel_samples','fullsel_samples']):\n",
    "\n",
    "                VARIABLES, BIN, RANGES, XTITS = moreFunctions.get_plots(plot_type)\n",
    "                tag = tag + '_fakedata{}'.format(FAKEDATASET[-1])\n",
    "                SAVEFIG = True\n",
    "                DRAWDATA = True\n",
    "                DRAWRATIO = True\n",
    "                SELECTLONGEST = True\n",
    "                DRAWSYS = False #need to load extra files\n",
    "                #If plot_sample is fullsel_samples, change tag to \"fullsel_samples to save time ;)\n",
    "                SAVEDIR = 'C:\\\\Users\\\\Ryan\\\\python-workspace\\\\PELEE-newmcfilteredsamples\\\\plots\\\\Fake-Data-{}\\\\Run{}\\\\'.format(FAKEDATASET[-1],RUN)\n",
    "                if not os.path.exists(SAVEDIR): os.makedirs(SAVEDIR)\n",
    "                QUERY, track_cuts = 'nslice == 1', None\n",
    "                KINDS = ['event_category','interaction'] #interaction, backtracked_pdg, event_category\n",
    "                KINDS = ['event_category']\n",
    "\n",
    "                if SELECTLONGEST:\n",
    "                    tag += '_longest'\n",
    "                else:\n",
    "                    tag += '_alltracks'\n",
    "                if not DRAWDATA:\n",
    "                    tag += \"_nodata\"\n",
    "                if DRAWSYS:\n",
    "                    tag += '_detsys'\n",
    "                #if 23 in np.array(plot_sample['mc']['category']): \n",
    "                #    tag += '_nproton'\n",
    "\n",
    "                for KIND in KINDS:\n",
    "                    if SAVEFIG and len(VARIABLES) > 1:\n",
    "                        pdf = matplotlib.backends.backend_pdf.PdfPages(SAVEDIR+\"combined_{}_{}.pdf\".format(tag,KIND))\n",
    "                    for (VARIABLE, BINS, RANGE, XTIT) in zip(VARIABLES, BIN, RANGES, XTITS):\n",
    "                    #####################################################################\n",
    "                        # lots of formatting things based on the tag\n",
    "                        if \"fullsel_above105_samples\" in tag.lower():\n",
    "                            print(\"using fullsel_above105_samples\")\n",
    "                            plot_sample = fullsel_above105_samples #or samples, or presel_sapmles, \n",
    "                            plot_title = r\"Fullsel INC (above 1.05 GeV reco E$_{\\nu}$)\"\n",
    "                        elif \"fullsel_sample\" in tag.lower():\n",
    "                            print(\"using fullsel_muon_samples\")\n",
    "                            plot_sample = fullsel_samples #or samples, or presel_sapmles, \n",
    "                            plot_title = r\"Fullsel $\\nu_{\\mu}$ CC INC\"\n",
    "                        elif \"ccqe_muon\" in tag.lower():\n",
    "                            print(\"using CCQE_muon_samples\")\n",
    "                            plot_sample = CCQE_muon_samples \n",
    "                            plot_title = \"CCQE muon\"\n",
    "                        elif \"ccqe_proton\" in tag.lower():\n",
    "                            print(\"using CCQE_proton_samples\")\n",
    "                            plot_sample = CCQE_proton_samples \n",
    "                            plot_title = \"CCQE proton\"\n",
    "                        elif \"ccqe_contained\" in tag.lower():\n",
    "                            plot_sample = CCQE_contained_samples \n",
    "                            plot_title = \"CCQE, contained tracks\"\n",
    "                        elif \"ccqe_sample\" in tag.lower():\n",
    "                            plot_sample = CCQE_samples \n",
    "                            plot_title = \"CCQE\"\n",
    "                        elif \"fullsel_nomcs_sample\" in tag.lower():\n",
    "                            print(\"using fullsel_noMCS_muon_samples\")\n",
    "                            plot_sample = fullsel_noMCS_samples \n",
    "                            plot_title = \"Fullsel, No MCS Cut, \"\n",
    "                        elif \"presel_contained_sample\" in tag.lower():\n",
    "                            print(\"using presel_contained_samples\")\n",
    "                            plot_sample = presel_contained_samples\n",
    "                            plot_title = \"Presel, Contained Tracks, \"\n",
    "                        elif \"ccqe_tracktester_contained\" in tag.lower():\n",
    "                            plot_sample = CCQE_tracktester_contained_samples\n",
    "                            plot_title = \"CCQE, trk_score > 0.5, contained\"\n",
    "                        elif \"ccqe_tracktester\" in tag.lower():\n",
    "                            plot_sample = CCQE_tracktester_samples\n",
    "                            plot_title = \"CCQE, trk_score > 0.5\"\n",
    "                        elif \"presel_sample\" in tag.lower():\n",
    "                            plot_sample = presel_samples\n",
    "                            plot_title = r\"Presel $\\nu_{\\mu}$ CC INC\"\n",
    "                        elif \"samples\" in tag.lower():\n",
    "                            plot_sample = samples\n",
    "                            if \"presel\" in ls.SAMPLE or PRESEL == True:\n",
    "                                plot_title = \"Presel\"\n",
    "                            else:\n",
    "                                plot_title = r\"Presel\"\n",
    "                        else:\n",
    "                            print(\"using default samples\")\n",
    "                            plot_sample = samples\n",
    "                            if \"presel\" in ls.SAMPLE:\n",
    "                                plot_title = \"Presel\"\n",
    "                            else:\n",
    "                                plot_title = \"NoSel\"\n",
    "\n",
    "                        if not SELECTLONGEST:\n",
    "                            plot_title += ', all tracks'\n",
    "                        if \"noopfilter\" in tag.lower():\n",
    "                            plot_title += ', no opfilter cuts'\n",
    "\n",
    "                        if VARIABLE not in samples['data'].keys(): samples['data'][VARIABLE] = -999\n",
    "\n",
    "                        if \"above105\" in tag.lower():\n",
    "                            XTIT += \" (reco_nu_e_range > 1.05 GeV)\"\n",
    "                        elif \"below105\" in tag.lower():\n",
    "                            XTIT += \" (reco_nu_e_range <= 1.05 GeV)\"\n",
    "                            if VARIABLE == 'reco_nu_e_range_v':\n",
    "                                BINS,  RANGE = 11, (-0.05, 1.05)\n",
    "\n",
    "                        if \"fullsel_samples\" in tag.lower():\n",
    "                            plot_sample = fullsel_samples\n",
    "                        elif \"fullsel_notopo_samples\" in tag.lower():\n",
    "                            plot_sample = fullsel_notopo_samples\n",
    "\n",
    "                        if \"nomcs\" in tag.lower():\n",
    "                            XTIT += \" no MCS cut\"\n",
    "                        elif \"invertmcs\" in tag.lower():\n",
    "                            XTIT += ' inverted MCS cut'\n",
    "\n",
    "                        if \"true2212\" in tag.lower():\n",
    "                            XTIT += ' (true leading proton) '\n",
    "\n",
    "                        if 'crtgt100' in tag.lower():\n",
    "                            XTIT += ' (crthitpe > 100)'\n",
    "                        elif 'crtlt100' in tag.lower():\n",
    "                            XTIT += ' (crthitpe < 100)'\n",
    "                        elif 'invertcrt' in tag.lower():\n",
    "                            XTIT += ' (crthitpe > 100 and crtveto == 0)'\n",
    "\n",
    "                        if 'nocrt' in tag.lower():\n",
    "                            plot_title += ', no CRT'\n",
    "                        plot_title += ', FD{}R{}'.format(FAKEDATASET,RUN)\n",
    "\n",
    "                        #get specific cuts based on what the tag is\n",
    "                        #QUERY, track_cuts = moreFunctions.get_Cuts(tag, ISRUN3)\n",
    "                        #######################################################\n",
    "                        # plotting\n",
    "                        my_plotter = moreFunctions.get_plotter(tag, plot_sample, pot, RUN, USECRT_temp, False)\n",
    "                        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "                            VARIABLE,   \n",
    "                            query=QUERY,\n",
    "                            kind=KIND, #sample, interaction, backtracked_pdg\n",
    "                            track_cuts = track_cuts,\n",
    "                            select_longest = SELECTLONGEST, #this is true by default in self._selection\n",
    "                            title=XTIT,\n",
    "                            #bins=asymm_bins,\n",
    "                            bins=BINS,\n",
    "                            stacksort=4, #0-numerical, 1-weights, 2-eLee on top, 3-eLee+nue on top, 4-numu on top\n",
    "                            range=RANGE,\n",
    "                            ratio=DRAWRATIO,\n",
    "                            draw_sys=DRAWSYS,\n",
    "                            #draw_data=DRAWDATA,\n",
    "                        )[0:3]\n",
    "                        print(\"Profile likelihood: {} sigma @ {} POT\".format(my_plotter.significance_likelihood,pot))\n",
    "                        print(\"s/sqrt(b): {} sigma @ {} POT\".format(my_plotter.significance, pot))\n",
    "\n",
    "                        #ax1.set_ylim(0,40)\n",
    "                        #ax1.set_yscale(\"log\")\n",
    "                        #ax1.set_ylim(0,12000)\n",
    "                        ax1.set_ylim(0,ax1.get_ylim()[1]*1.5)\n",
    "                        #ax2.set_ylim(0.5,1.5)\n",
    "                        ax1.set_title(plot_title, fontsize=15)\n",
    "\n",
    "                        if SAVEFIG:\n",
    "                            fn = VARIABLE+\"_\"+date_time+\"_\"+tag+'_'+KIND\n",
    "                            fn += \".pdf\"\n",
    "                            print(\"saving to {}...\".format(SAVEDIR+fn))\n",
    "                            fig.tight_layout()\n",
    "                            fig.savefig(SAVEDIR+fn)\n",
    "                            if len(VARIABLES) > 1:\n",
    "                                pdf.savefig(fig)\n",
    "                        plt.show()\n",
    "\n",
    "                    if SAVEFIG and len(VARIABLES) > 1:\n",
    "                        pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
