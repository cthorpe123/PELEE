{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two showers sideband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING BDT?\n",
    "USEBDT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cale to MCC8 CV?\n",
    "MCC8WEIGHTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = ls.fold\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "R3BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_beam_good_reco2_1e19'\n",
    "R3EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_G_all_reco2'\n",
    "R3NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "R3NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "R3CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "R3CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run3_reco2_reco2'\n",
    "R3CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "R3NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "R3NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "\n",
    "ur3mc = uproot.open(ls.ntuple_path+ls.RUN3+R3NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nue = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3data = uproot.open(ls.ntuple_path+ls.RUN3+R3BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ext = uproot.open(ls.ntuple_path+ls.RUN3+R3EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3dirt = uproot.open(ls.ntuple_path+ls.RUN3+R3DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3lee = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3cccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R2NU = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2\"\n",
    "R2NUE = \"prodgenie_bnb_intrinsic_nue_overlay_run2_v08_00_00_35_run2a_reco2_reco2\"\n",
    "\n",
    "ur2mc = uproot.open(ls.ntuple_path+ls.RUN2+R2NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2nue = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2lee = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R1BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2'\n",
    "R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C1_C2_D1_D2_E1_E2_all_reco2' #Run1 + Run2\n",
    "R1NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "R1NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "R1CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "R1CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run1_reco2_reco2'\n",
    "R1CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "ur1mc = uproot.open(ls.ntuple_path+ls.RUN1+R1NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nue = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1data = uproot.open(ls.ntuple_path+ls.RUN1+R1BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ext = uproot.open(ls.ntuple_path+ls.RUN1+R1EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1dirt = uproot.open(ls.ntuple_path+ls.RUN1+R1DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1lee = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1cccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R123_TWO_SHOWERS_SIDEBAND_BNB = '1e_2showers_sidebands'\n",
    "ur123data_two_showers_sidebands = uproot.open(ls.ntuple_path+'data_sidebands/'+R123_TWO_SHOWERS_SIDEBAND_BNB+\".root\")['nuselection'][tree]\n",
    "\n",
    "variables = [\n",
    "    \"shr_dedx_Y\", \"shr_bkt_pdg\", \"p\", \"pt\", \"selected\", \"nu_pdg\", \"shr_theta\",\n",
    "    \"slpdg\", \"trk_score_v\", \"backtracked_pdg\", # modified from shr_score_v\n",
    "    \"shr_pfp_id_v\", \"category\",\n",
    "    \"shr_tkfit_dedx_U\",\"shr_tkfit_dedx_V\",\"shr_tkfit_dedx_Y\",\n",
    "    \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "    \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "    #\"shr_energy_tot\", \n",
    "    \"trk_energy_tot\", \"shr_hits_tot\", \"ccnc\", \"trk_chipr\",\n",
    "    \"trk_bkt_pdg\", \"hits_ratio\", \"n_tracks_contained\", \n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy0\",\"NeutrinoEnergy1\",\"NeutrinoEnergy2\",\n",
    "    #\"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    #\"trk_pfp_id\",\n",
    "    \"shrmoliereavg\",\"shrmoliererms\",\n",
    "    \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "    \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "    \"trkshrhitdist2\", \"trkshrhitdist0\",\"trkshrhitdist1\", #distance between track and shower in 2D\n",
    "    \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    \"pi0_energy2_Y\",\"pi0_energy1_Y\",\"pi0_gammadot\", # pi0 tagger variables\n",
    "    \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "    \"hits_u\", \"hits_v\", \"hits_y\", \"shr_pz\", \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "    \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"run\", \"sub\", \"evt\", \"nproton\", \"trk_pid_chipr_v\",\n",
    "    \"trk_len\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"shr_score\", \"trk_score\", \"trk_hits_tot\",\n",
    "    \"true_e_visible\", \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\", \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\"contained_fraction\",\n",
    "    \"secondshower_U_nhit\",\"secondshower_U_vtxdist\",\"secondshower_U_dot\",\"secondshower_U_dir\",\"shrclusdir0\",\n",
    "    \"secondshower_V_nhit\",\"secondshower_V_vtxdist\",\"secondshower_V_dot\",\"secondshower_V_dir\",\"shrclusdir1\",\n",
    "    \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "    \"shr_tkfit_nhits_Y\",\"shr_tkfit_nhits_U\",\"shr_tkfit_nhits_V\",\n",
    "    \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "    \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\",\n",
    "    \"trk_sce_start_x_v\",\"trk_sce_start_y_v\",\"trk_sce_start_z_v\",\n",
    "    \"trk_sce_end_x_v\",\"trk_sce_end_y_v\",\"trk_sce_end_z_v\",\"shr_id\",\n",
    "    \"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\",\n",
    "    \"trk_hits_tot\", \"trk_hits_u_tot\", \"trk_hits_v_tot\", \"trk_hits_y_tot\",\n",
    "    \"shr_hits_tot\", \"shr_hits_u_tot\", \"shr_hits_v_tot\", \"shr_hits_y_tot\",\n",
    "]\n",
    "#make the list unique\n",
    "variables = list(set(variables))\n",
    "print(variables)\n",
    "\n",
    "variables.remove(\"_closestNuCosmicDist\")\n",
    "variables.remove(\"crtveto\")\n",
    "variables.remove(\"crthitpe\")\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "\n",
    "r3nue = ur3nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3mc = ur3mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r3ncpi0 = ur3ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccpi0 = ur3ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccnopi = ur3ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3cccpi = ur3cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ncnopi = ur3ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3nccpi = ur3nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3data = ur3data.pandas.df(variables, flatten=False)\n",
    "r3ext = ur3ext.pandas.df(variables, flatten=False)\n",
    "r3dirt = ur3dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3lee = ur3lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r3lee[\"is_signal\"] = r3lee[\"category\"] == 11\n",
    "r3data[\"is_signal\"] = r3data[\"category\"] == 11\n",
    "r3nue[\"is_signal\"] = r3nue[\"category\"] == 11\n",
    "r3mc[\"is_signal\"] = r3mc[\"category\"] == 11\n",
    "r3dirt[\"is_signal\"] = r3dirt[\"category\"] == 11\n",
    "r3ext[\"is_signal\"] = r3ext[\"category\"] == 11\n",
    "r3ncpi0[\"is_signal\"] = r3ncpi0[\"category\"] == 11\n",
    "r3ccpi0[\"is_signal\"] = r3ccpi0[\"category\"] == 11\n",
    "r3ccnopi[\"is_signal\"] = r3ccnopi[\"category\"] == 11\n",
    "r3cccpi[\"is_signal\"] = r3cccpi[\"category\"] == 11\n",
    "r3ncnopi[\"is_signal\"] = r3ncnopi[\"category\"] == 11\n",
    "r3nccpi[\"is_signal\"] = r3nccpi[\"category\"] == 11\n",
    "r3lee.loc[r3lee['category'] == 1, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 10, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur3lee,ur3mc,ur3ncpi0,ur3ccpi0,ur3ccnopi,ur3cccpi,ur3ncnopi,ur3nccpi,ur3nue,ur3ext,ur3data,ur3dirt]\n",
    "df_v = [r3lee,r3mc,r3ncpi0,r3ccpi0,r3ccnopi,r3cccpi,r3ncnopi,r3nccpi,r3nue,r3ext,r3data,r3dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "    trk_sce_start_x_v = up.array('trk_sce_start_x_v')\n",
    "    trk_sce_start_y_v = up.array('trk_sce_start_y_v')\n",
    "    trk_sce_start_z_v = up.array('trk_sce_start_z_v')\n",
    "    trk_sce_end_x_v = up.array('trk_sce_end_x_v')\n",
    "    trk_sce_end_y_v = up.array('trk_sce_end_y_v')\n",
    "    trk_sce_end_z_v = up.array('trk_sce_end_z_v')\n",
    "    trk_sce_start_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_x_v,shr_id)])\n",
    "    trk_sce_start_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_y_v,shr_id)])\n",
    "    trk_sce_start_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_z_v,shr_id)])\n",
    "    trk_sce_end_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_x_v,shr_id)])\n",
    "    trk_sce_end_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_y_v,shr_id)])\n",
    "    trk_sce_end_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_z_v,shr_id)])\n",
    "    df['shr_trk_sce_start_x'] = trk_sce_start_x_v_sel\n",
    "    df['shr_trk_sce_start_y'] = trk_sce_start_y_v_sel\n",
    "    df['shr_trk_sce_start_z'] = trk_sce_start_z_v_sel\n",
    "    df['shr_trk_sce_end_x'] = trk_sce_end_x_v_sel\n",
    "    df['shr_trk_sce_end_y'] = trk_sce_end_y_v_sel\n",
    "    df['shr_trk_sce_end_z'] = trk_sce_end_z_v_sel   \n",
    "\n",
    "if (USEBDT == True):\n",
    "    train_r3ccpi0, r3ccpi0 = train_test_split(r3ccpi0, test_size=0.5, random_state=1990)\n",
    "    \n",
    "r1nue = ur1nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1mc = ur1mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r1ncpi0 = ur1ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccpi0 = ur1ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccnopi = ur1ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1cccpi = ur1cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ncnopi = ur1ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1nccpi = ur1nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1data = ur1data.pandas.df(variables, flatten=False)\n",
    "r1ext = ur1ext.pandas.df(variables, flatten=False)\n",
    "r1dirt = ur1dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1lee = ur1lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "\n",
    "r123data_two_showers_sidebands = ur123data_two_showers_sidebands.pandas.df(variables, flatten=False)\n",
    "\n",
    "r1lee[\"is_signal\"] = r1lee[\"category\"] == 11\n",
    "r1data[\"is_signal\"] = r1data[\"category\"] == 11\n",
    "r1nue[\"is_signal\"] = r1nue[\"category\"] == 11\n",
    "r1mc[\"is_signal\"] = r1mc[\"category\"] == 11\n",
    "r1dirt[\"is_signal\"] = r1dirt[\"category\"] == 11\n",
    "r1ext[\"is_signal\"] = r1ext[\"category\"] == 11\n",
    "r1ncpi0[\"is_signal\"] = r1ncpi0[\"category\"] == 11\n",
    "r1ccpi0[\"is_signal\"] = r1ccpi0[\"category\"] == 11\n",
    "r1ccnopi[\"is_signal\"] = r1ccnopi[\"category\"] == 11\n",
    "r1cccpi[\"is_signal\"] = r1cccpi[\"category\"] == 11\n",
    "r1ncnopi[\"is_signal\"] = r1ncnopi[\"category\"] == 11\n",
    "r1nccpi[\"is_signal\"] = r1nccpi[\"category\"] == 11\n",
    "r1lee.loc[r1lee['category'] == 1, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 10, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "r123data_two_showers_sidebands[\"is_signal\"] = r123data_two_showers_sidebands[\"category\"] == 11\n",
    "\n",
    "uproot_v = [ur1lee,ur1mc,ur1ncpi0,ur1ccpi0,ur1ccnopi,ur1cccpi,ur1ncnopi,ur1nccpi,ur1nue,ur1ext,ur1data,ur1dirt, ur123data_two_showers_sidebands]\n",
    "df_v = [r1lee,r1mc,r1ncpi0,r1ccpi0,r1ccnopi,r1cccpi,r1ncnopi,r1nccpi,r1nue,r1ext,r1data,r1dirt, r123data_two_showers_sidebands]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "    trk_sce_start_x_v = up.array('trk_sce_start_x_v')\n",
    "    trk_sce_start_y_v = up.array('trk_sce_start_y_v')\n",
    "    trk_sce_start_z_v = up.array('trk_sce_start_z_v')\n",
    "    trk_sce_end_x_v = up.array('trk_sce_end_x_v')\n",
    "    trk_sce_end_y_v = up.array('trk_sce_end_y_v')\n",
    "    trk_sce_end_z_v = up.array('trk_sce_end_z_v')\n",
    "    trk_sce_start_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_x_v,shr_id)])\n",
    "    trk_sce_start_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_y_v,shr_id)])\n",
    "    trk_sce_start_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_z_v,shr_id)])\n",
    "    trk_sce_end_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_x_v,shr_id)])\n",
    "    trk_sce_end_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_y_v,shr_id)])\n",
    "    trk_sce_end_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_z_v,shr_id)])\n",
    "    df['shr_trk_sce_start_x'] = trk_sce_start_x_v_sel\n",
    "    df['shr_trk_sce_start_y'] = trk_sce_start_y_v_sel\n",
    "    df['shr_trk_sce_start_z'] = trk_sce_start_z_v_sel\n",
    "    df['shr_trk_sce_end_x'] = trk_sce_end_x_v_sel\n",
    "    df['shr_trk_sce_end_y'] = trk_sce_end_y_v_sel\n",
    "    df['shr_trk_sce_end_z'] = trk_sce_end_z_v_sel   \n",
    "\n",
    "\n",
    "r2nue = ur2nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r2mc = ur2mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r2lee = ur2lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r2lee[\"is_signal\"] = r2lee[\"category\"] == 11\n",
    "r2nue[\"is_signal\"] = r2nue[\"category\"] == 11\n",
    "r2mc[\"is_signal\"] = r2mc[\"category\"] == 11\n",
    "r2lee.loc[r2lee['category'] == 1, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 10, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur2lee,ur2mc,ur2nue]\n",
    "df_v = [r2lee,r2mc,r2nue]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    trk_llr_pid_v = up.array('trk_llr_pid_score_v')\n",
    "    trk_calo_energy_y_v = up.array('trk_calo_energy_y_v')\n",
    "    trk_energy_proton_v = up.array('trk_energy_proton_v')\n",
    "    #shr_moliere_avg_v = up.array('shr_moliere_avg_v')\n",
    "    trk_id = up.array('trk_id')-1 # I think we need this -1 to get the right result\n",
    "    shr_id = up.array('shr_id')-1 # I think we need this -1 to get the right result\n",
    "    trk_llr_pid_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_llr_pid_v,trk_id)])\n",
    "    trk_calo_energy_y_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_calo_energy_y_v,trk_id)])\n",
    "    trk_energy_proton_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(trk_energy_proton_v,trk_id)])\n",
    "    #shr_moliere_avg_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else 9999. for pidv,tid in zip(shr_moliere_avg_v,shr_id)])\n",
    "    df['trkpid'] = trk_llr_pid_v_sel\n",
    "    df['trackcaloenergy'] = trk_calo_energy_y_sel\n",
    "    df['protonenergy'] = trk_energy_proton_sel\n",
    "    #df['shrmoliereavg'] = shr_moliere_avg_sel\n",
    "    trk_sce_start_x_v = up.array('trk_sce_start_x_v')\n",
    "    trk_sce_start_y_v = up.array('trk_sce_start_y_v')\n",
    "    trk_sce_start_z_v = up.array('trk_sce_start_z_v')\n",
    "    trk_sce_end_x_v = up.array('trk_sce_end_x_v')\n",
    "    trk_sce_end_y_v = up.array('trk_sce_end_y_v')\n",
    "    trk_sce_end_z_v = up.array('trk_sce_end_z_v')\n",
    "    trk_sce_start_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_x_v,shr_id)])\n",
    "    trk_sce_start_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_y_v,shr_id)])\n",
    "    trk_sce_start_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_start_z_v,shr_id)])\n",
    "    trk_sce_end_x_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_x_v,shr_id)])\n",
    "    trk_sce_end_y_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_y_v,shr_id)])\n",
    "    trk_sce_end_z_v_sel = awkward.fromiter([pidv[tid] if tid<len(pidv) else -9999. for pidv,tid in zip(trk_sce_end_z_v,shr_id)])\n",
    "    df['shr_trk_sce_start_x'] = trk_sce_start_x_v_sel\n",
    "    df['shr_trk_sce_start_y'] = trk_sce_start_y_v_sel\n",
    "    df['shr_trk_sce_start_z'] = trk_sce_start_z_v_sel\n",
    "    df['shr_trk_sce_end_x'] = trk_sce_end_x_v_sel\n",
    "    df['shr_trk_sce_end_y'] = trk_sce_end_y_v_sel\n",
    "    df['shr_trk_sce_end_z'] = trk_sce_end_z_v_sel   \n",
    "    \n",
    "    \n",
    "nue = pd.concat([r1nue,r2nue,r3nue],ignore_index=True)\n",
    "#nue = pd.concat([r3nue,r1nue],ignore_index=True)\n",
    "mc = pd.concat([r3mc,r2mc,r1mc],ignore_index=True)\n",
    "#mc = pd.concat([r3mc,r1mc],ignore_index=True)\n",
    "ncpi0 = pd.concat([r3ncpi0,r1ncpi0],ignore_index=True)\n",
    "ccpi0 = pd.concat([r3ccpi0,r1ccpi0],ignore_index=True)\n",
    "ccnopi = pd.concat([r3ccnopi,r1ccnopi],ignore_index=True)\n",
    "cccpi = pd.concat([r3cccpi,r1cccpi],ignore_index=True)\n",
    "ncnopi = pd.concat([r3ncnopi,r1ncnopi],ignore_index=True)\n",
    "nccpi = pd.concat([r3nccpi,r1nccpi],ignore_index=True)\n",
    "# data = pd.concat([r3data,r1data],ignore_index=True)\n",
    "data = pd.concat([r123data_two_showers_sidebands],ignore_index=True)\n",
    "ext = pd.concat([r3ext,r1ext],ignore_index=True)\n",
    "dirt = pd.concat([r3dirt,r1dirt],ignore_index=True)\n",
    "lee = pd.concat([r1lee,r2lee,r3lee],ignore_index=True)\n",
    "#lee = pd.concat([r3lee,r1lee],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    #df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune'] * 0.759\n",
    "#     df.loc[ df['npi0'] > 0, 'weightSplineTimesTune' ] = df['weightSpline'] * df['weightTune']\n",
    "    #df['weightSpline']  = df['weightSpline']  * df['weightTune']\n",
    "    #print(\"!!!! WARNING!!! reweighting based on NeutrinoEnergy2 !!!!\")\n",
    "    #df['weightSplineTimesTune'] = df['weightSplineTimesTune']*(1.2-(0.7/2000)*df['NeutrinoEnergy2'])\n",
    "    #print(\"!!!! WARNING!!! reweighting based on pi0_e !!!!\")\n",
    "    #df.loc[ df['pi0_e'] > 0.1, 'weightSplineTimesTune' ] = df['weightSplineTimesTune']*(1.-0.35*df['pi0_e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust from MCC9 CV to MCC8 CV\n",
    "\n",
    "if (MCC8WEIGHTS == True):\n",
    "\n",
    "    # scaling for QE\n",
    "    CV_bins = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,5.0]\n",
    "    CV_scaling = [2.5,2.0,1.7,1.45,1.3,1.25,1.175,1.15,1.14,1.1]\n",
    "    # scaling for RES\n",
    "\n",
    "    mc.loc[ (mc['interaction'] == 10), 'weightSpline' ] = 2 * mc['weightSpline']\n",
    "    ncpi0.loc[ (ncpi0['interaction'] == 10), 'weightSpline' ] = 2 * ncpi0['weightSpline']\n",
    "    ccpi0.loc[ (ccpi0['interaction'] == 10), 'weightSpline' ] = 2 * ccpi0['weightSpline']\n",
    "    ccnopi.loc[ (ccnopi['interaction'] == 10), 'weightSpline' ] = 2 * ccnopi['weightSpline']\n",
    "    cccpi.loc[ (cccpi['interaction'] == 10), 'weightSpline' ] = 2 * cccpi['weightSpline']\n",
    "    ncnopi.loc[ (ncnopi['interaction'] == 10), 'weightSpline' ] = 2 * ncnopi['weightSpline']\n",
    "    nccpi.loc[ (nccpi['interaction'] == 10), 'weightSpline' ] = 2 * nccpi['weightSpline']\n",
    "    nue.loc[ (nue['interaction'] == 10), 'weightSpline' ] = 2 * nue['weightSpline']\n",
    "    lee.loc[ (lee['interaction'] == 10), 'weightSpline' ] = 2 * lee['weightSpline']\n",
    "    dirt.loc[ (dirt['interaction'] == 10), 'weightSpline' ] = 2 * dirt['weightSpline']\n",
    "\n",
    "    for i, CV_bin in enumerate(CV_bins):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        mc.loc[ (mc['nu_e'] > CV_bins[i-1]) & (mc['nu_e'] < CV_bins[i]) & (mc['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * mc['weightSpline']\n",
    "        nue.loc[ (nue['nu_e'] > CV_bins[i-1]) & (nue['nu_e'] < CV_bins[i]) & (nue['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nue['weightSpline']\n",
    "        ncpi0.loc[ (nc['nu_e'] > CV_bins[i-1]) & (ncpi0['nu_e'] < CV_bins[i]) & (ncpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncpi0['weightSpline']\n",
    "        ccpi0.loc[ (ccpi0['nu_e'] > CV_bins[i-1]) & (ccpi0['nu_e'] < CV_bins[i]) & (ccpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccpi0['weightSpline']\n",
    "        ccnopi.loc[ (ccnopi['nu_e'] > CV_bins[i-1]) & (ccnopi['nu_e'] < CV_bins[i]) & (ccnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccnopi['weightSpline']\n",
    "        cccpi.loc[ (cccpi['nu_e'] > CV_bins[i-1]) & (cccpi['nu_e'] < CV_bins[i]) & (cccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * cccpi['weightSpline']\n",
    "        ncnopi.loc[ (ncnopi['nu_e'] > CV_bins[i-1]) & (ncnopi['nu_e'] < CV_bins[i]) & (ncnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncnopi['weightSpline']\n",
    "        nccpi.loc[ (nccpi['nu_e'] > CV_bins[i-1]) & (nccpi['nu_e'] < CV_bins[i]) & (nccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nccpi['weightSpline']\n",
    "        lee.loc[ (lee['nu_e'] > CV_bins[i-1]) & (lee['nu_e'] < CV_bins[i]) & (lee['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * lee['weightSpline']\n",
    "        dirt.loc[ (dirt['nu_e'] > CV_bins[i-1]) & (dirt['nu_e'] < CV_bins[i]) & (dirt['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * dirt['weightSpline']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#df_v = [lee,mc,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    # and the 2d angle difference\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(df_v):\n",
    "    df[\"ptOverP\"] = df[\"pt\"]/df[\"p\"]\n",
    "    df[\"phi1MinusPhi2\"] = df[\"shr_phi\"]-df[\"trk_phi\"]\n",
    "    df[\"theta1PlusTheta2\"] = df[\"shr_theta\"]+df[\"trk_theta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df['shr_tkfit_nhits_tot'] = (df['shr_tkfit_nhits_Y']+df['shr_tkfit_nhits_U']+df['shr_tkfit_nhits_V'])\n",
    "    df['shr_tkfit_dedx_avg'] = (df['shr_tkfit_nhits_Y']*df['shr_tkfit_dedx_Y'] + df['shr_tkfit_nhits_U']*df['shr_tkfit_dedx_U'] + df['shr_tkfit_nhits_V']*df['shr_tkfit_dedx_V'])/df['shr_tkfit_nhits_tot']\n",
    "    df['shr_tkfit_2cm_nhits_tot'] = (df['shr_tkfit_2cm_nhits_Y']+df['shr_tkfit_2cm_nhits_U']+df['shr_tkfit_2cm_nhits_V'])\n",
    "    df['shr_tkfit_2cm_dedx_avg'] = (df['shr_tkfit_2cm_nhits_Y']*df['shr_tkfit_2cm_dedx_Y'] + df['shr_tkfit_2cm_nhits_U']*df['shr_tkfit_2cm_dedx_U'] + df['shr_tkfit_2cm_nhits_V']*df['shr_tkfit_2cm_dedx_V'])/df['shr_tkfit_2cm_nhits_tot']\n",
    "    df['shr_tkfit_gap10_nhits_tot'] = (df['shr_tkfit_gap10_nhits_Y']+df['shr_tkfit_gap10_nhits_U']+df['shr_tkfit_gap10_nhits_V'])\n",
    "    df['shr_tkfit_gap10_dedx_avg'] = (df['shr_tkfit_gap10_nhits_Y']*df['shr_tkfit_gap10_dedx_Y'] + df['shr_tkfit_gap10_nhits_U']*df['shr_tkfit_gap10_dedx_U'] + df['shr_tkfit_gap10_nhits_V']*df['shr_tkfit_gap10_dedx_V'])/df['shr_tkfit_gap10_nhits_tot']\n",
    "    df.loc[:,'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_nhits_U']>df['shr_tkfit_nhits_Y']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_Y']) & (df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_U']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERCEPT = 0.0\n",
    "SLOPE = 0.83\n",
    "\n",
    "# define some energy-related variables\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + df[\"trk_energy_tot\"]\n",
    "    df[\"reco_e_qe\"] = 0.938*((df[\"shr_energy\"]+INTERCEPT)/SLOPE)/(0.938 - ((df[\"shr_energy\"]+INTERCEPT)/SLOPE)*(1-np.cos(df[\"shr_theta\"])))\n",
    "    df[\"reco_e_rqe\"] = df[\"reco_e_qe\"]/df[\"reco_e\"]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"shr_energy\"])\n",
    "ext[\"extdata\"] = np.ones_like(ext[\"shr_energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(df_v):\n",
    "    df['asymm'] = np.abs(df['pi0_energy1_Y']-df['pi0_energy2_Y'])/(df['pi0_energy1_Y']+df['pi0_energy2_Y'])\n",
    "    df['pi0energy'] = 134.98 * np.sqrt( 2. / ( (1-(df['asymm'])**2) * (1-df['pi0_gammadot']) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "## avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "cccpi = cccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be trained on\n",
    "TRAINVAR = [\"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_dedx_max\",\n",
    "            \"trkfit\",\"trkpid\",\n",
    "            \"subcluster\",\"shrmoliereavg\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcI43ileYJ9P"
   },
   "outputs": [],
   "source": [
    "LABELS =  ['pi0','nonpi0']\n",
    "#LABELS =  [\"bkg\"]\n",
    "\n",
    "if (USEBDT == True):\n",
    "    for label, bkg_query in zip(LABELS, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            mc[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(mc[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nue[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nue[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ext[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ext[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            data[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(data[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            dirt[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(dirt[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            lee[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(lee[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            cccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(cccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0p BDT\n",
    "\n",
    "TRAINVARZP = ['shrmoliereavg','shr_score', \"trkfit\",\"subcluster\",\n",
    "              \"CosmicIPAll3D\",\"CosmicDirAll3D\",\n",
    "              'secondshower_Y_nhit','secondshower_Y_vtxdist','secondshower_Y_dot','anglediff_Y',\n",
    "              'secondshower_V_nhit','secondshower_V_vtxdist','secondshower_V_dot','anglediff_V',\n",
    "              'secondshower_U_nhit','secondshower_U_vtxdist','secondshower_U_dot','anglediff_U',\n",
    "              \"shr_tkfit_2cm_dedx_U\", \"shr_tkfit_2cm_dedx_V\", \"shr_tkfit_2cm_dedx_Y\",\n",
    "              \"shr_tkfit_gap10_dedx_U\", \"shr_tkfit_gap10_dedx_V\", \"shr_tkfit_gap10_dedx_Y\",\n",
    "              \"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\"]\n",
    "\n",
    "LABELSZP = ['bkg']\n",
    "\n",
    "if (USEBDT == True):\n",
    "    for label, bkg_query in zip(LABELSZP, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi_vx.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            mc[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(mc[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nue[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nue[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ext[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ext[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            data[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(data[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            dirt[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(dirt[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            lee[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(lee[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncpi0[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccpi0[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccnopi[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            cccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(cccpi[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncnopi[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nccpi[TRAINVARZP]),\n",
    "                ntree_limit=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"cccpi\": cccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "#scaling = 101.0/4.21 #0218\n",
    "# scaling = 101.0/4.84 #0304\n",
    "#scaling = 69.6/4.84 #0304\n",
    "#scaling = 125.0/4.84 #0304\n",
    "scaling = 1\n",
    "\n",
    "SPLIT = 1.0\n",
    "if (USEBDT == True):\n",
    "    SPLIT = 1.48\n",
    "\n",
    "#''' 0304\n",
    "weights = {\n",
    "    \"mc\": 1.61e-01 * scaling, \n",
    "    \"ext\": 5.01e-01 * scaling, \n",
    "    \"nue\": 3.32e-03 * scaling,\n",
    "    \"lee\": 3.32e-03 * scaling,\n",
    "    \"dirt\": 9.09e-01 * scaling,\n",
    "    \"ncpi0\": 1.19e-01 * scaling,\n",
    "    \"ccpi0\": 5.92e-02 * SPLIT * scaling,\n",
    "    \"ncnopi\": 5.60e-02 * scaling,\n",
    "    \"nccpi\": 2.58e-02 * scaling,\n",
    "    \"ccnopi\": 6.48e-02 * scaling,\n",
    "    \"cccpi\": 5.18e-02 * scaling,\n",
    "}\n",
    "pot = 5.88e20*scaling\n",
    "\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unblinding_far_sideband import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = False\n",
    "no_leg = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_set = []\n",
    "variables_set.append('insensitive_variables')\n",
    "variables_set.append('input_bdt')\n",
    "variables_set.append('bdt_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_ylim = {}\n",
    "for which_variables in variables_set:\n",
    "    this_folder = ls.plots_path+'PELEE_two_showers_sideband_unblinding/'\n",
    "    if no_data:\n",
    "        this_folder += 'dry_run/'\n",
    "    else:\n",
    "        this_folder += 'with_data/'\n",
    "    this_folder += (which_variables + '/')\n",
    "    !mkdir -p $this_folder\n",
    "    \n",
    "    this_query = PRESQ_twoplus\n",
    "    this_title = 'Two+ showers sideband\\n' + r'$\\nu_e$ preselection and N-showers contained >= 2'\n",
    "\n",
    "    if no_data:\n",
    "        this_query += ' and bnbdata==0'\n",
    "    \n",
    "    print(which_variables)\n",
    "    this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "    for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "        print(VARIABLE, BINS, RANGE, XTIT)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=this_query,\n",
    "            kind=\"event_category\",\n",
    "            draw_sys=True,\n",
    "            stacksort=3,\n",
    "            title=XTIT,\n",
    "            bins=BINS,\n",
    "            range=RANGE,\n",
    "        )[0:3]\n",
    "        \n",
    "        if no_leg:\n",
    "            ax1.legend().set_visible(False) \n",
    "        else:\n",
    "            ax1.set_title(this_title, loc='left')\n",
    "            ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "        \n",
    "        database_ylim[VARIABLE] = ax1.get_ylim()[1]\n",
    "        plt.tight_layout()\n",
    "        save_path = this_folder+VARIABLE\n",
    "        if no_leg:\n",
    "            save_path += '_noleg'\n",
    "        fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_ylim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Plotting with pi0 normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unblinding_far_sideband import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_set = []\n",
    "variables_set.append('insensitive_variables')\n",
    "variables_set.append('input_bdt')\n",
    "variables_set.append('bdt_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_variables in variables_set:\n",
    "    this_folder = ls.plots_path+'PELEE_two_showers_sideband_unblinding/'\n",
    "    this_folder += 'with_pi0_scaling/'\n",
    "    this_folder += (which_variables + '/')\n",
    "    !mkdir -p $this_folder\n",
    "    \n",
    "    this_query = PRESQ_twoplus\n",
    "    this_title = 'Two+ showers sideband\\n' + r'$\\nu_e$ preselection and N-showers contained >= 2' + '\\n' + r'$\\pi^0$ scaled by 0.759'\n",
    "\n",
    "    if no_data:\n",
    "        this_query += ' and bnbdata==0'\n",
    "    \n",
    "    print(which_variables)\n",
    "    this_plot_variables = plot_variables[which_variables]\n",
    "\n",
    "    for VARIABLE, BINS, RANGE, XTIT in this_plot_variables:\n",
    "        print(VARIABLE, BINS, RANGE, XTIT)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=this_query,\n",
    "            kind=\"event_category\",\n",
    "            draw_sys=True,\n",
    "            stacksort=3,\n",
    "            title=XTIT,\n",
    "            bins=BINS,\n",
    "            range=RANGE,\n",
    "        )[0:3]\n",
    "        \n",
    "        if no_leg:\n",
    "            ax1.legend().set_visible(False) \n",
    "            if VARIABLE in database_ylim.keys():\n",
    "                ax1.set_ylim(0, database_ylim[VARIABLE])\n",
    "        else:\n",
    "            ax1.set_title(this_title, loc='left')\n",
    "            if VARIABLE in database_ylim.keys():\n",
    "                ax1.set_ylim(0, database_ylim[VARIABLE])\n",
    "            else:\n",
    "                ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        save_path = this_folder+VARIABLE\n",
    "        if no_leg:\n",
    "            save_path += '_noleg'\n",
    "        fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf') \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With detector systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#dedx after far energy\n",
    "detsys = {\n",
    "    'nue': [1.27647279, 0.30363571, 0.38239875, 0.30185093, 0.25290227, 0.16252713,\n",
    " 0.14619229, 0.15608208, 0.1666133,  0.25468685, 0.07858252, 0.19893852,\n",
    " 0.25641127, 0.38413905, 0.2106816,  0.17191569, 0.45140248, 0.18510883,\n",
    " 0.63619039, 0.43327993,],\n",
    "\n",
    "    'ncpi0': [0.26039416, 0.26278514, 0.30491969, 0.1812784,  0.13276332, 0.17456273,\n",
    " 0.14327807, 0.30043894, 0.22668279, 0.3052821,  0.26732865, 0.27633069,\n",
    " 0.35367288, 0.29618235, 0.44247323, 0.54736577, 0.42008001, 0.3981663,\n",
    " 0.42393282, 0.36643562,],\n",
    "\n",
    "    'ccpi0': [0.26039416, 0.26278514, 0.30491969, 0.1812784,  0.13276332, 0.17456273,\n",
    " 0.14327807, 0.30043894, 0.22668279, 0.3052821,  0.26732865, 0.27633069,\n",
    " 0.35367288, 0.29618235, 0.44247323, 0.54736577, 0.42008001, 0.3981663,\n",
    " 0.42393282, 0.36643562,]\n",
    "\n",
    "}\n",
    "\n",
    "stage = 1\n",
    "no_leg = True\n",
    "# this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "# this_folder += 'with_pi0_scaling/'\n",
    "# this_folder += 'stage_{}/'.format(stage)\n",
    "# !mkdir -p $this_folder\n",
    "\n",
    "this_query = PRESQ_twoplus\n",
    "this_title = 'Two+ showers sideband\\n' + r'$\\nu_e$ preselection and N-showers contained >= 2' + '\\n' + r'$\\pi^0$ scaled by 0.759'\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'shr_tkfit_dedx_max',20,(0,10),\"shr tkfit dE/dx (max, 0-4 cm) [MeV/cm]\",\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "# ax1.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "# save_path = this_folder+VARIABLE\n",
    "# if no_leg:\n",
    "#     save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#dedx after far energy\n",
    "detsys = {\n",
    "    'nue': [       0.0, 0.86010721, 0.28074609, 0.15415369, 0.14866511, 0.13024779,\n",
    " 0.03968399, 0.20109395, 0.06240319, 0.05555004, 0.07303715, 0.06233061,\n",
    " 0.04176388, 0.09383196, 0.07945567, 0.14401069, 0.1034272,  0.11883343,\n",
    " 0.08160861,0.11725796,0.10158504,0.12221902,\n",
    "],\n",
    "\n",
    "    'ncpi0': [0, 0.09882663, 0.18763546, 0.05706328, 0.0360522,  0.06301856,\n",
    " 0.10416693, 0.04895403, 0.03464493, 0.07523434, 0.05874881, 0.02683672,\n",
    " 0.02940983, 0.0624202,  0.07149102, 0.13125437, 0.11695622, 0.19981863,\n",
    " 0.30545354, 0.16143183, 0.21489781, 0.28976165,],\n",
    "\n",
    "    'ccpi0': [0, 0.09882663, 0.18763546, 0.05706328, 0.0360522,  0.06301856,\n",
    " 0.10416693, 0.04895403, 0.03464493, 0.07523434, 0.05874881, 0.02683672,\n",
    " 0.02940983, 0.0624202,  0.07149102, 0.13125437, 0.11695622, 0.19981863,\n",
    " 0.30545354, 0.16143183, 0.21489781, 0.28976165,],\n",
    "\n",
    "}\n",
    "\n",
    "stage = 1\n",
    "no_leg = True\n",
    "# this_folder = ls.plots_path+'PELEE_far_sideband_unblinding/'\n",
    "# this_folder += 'with_pi0_scaling/'\n",
    "# this_folder += 'stage_{}/'.format(stage)\n",
    "# !mkdir -p $this_folder\n",
    "\n",
    "this_query = PRESQ_twoplus\n",
    "this_title = 'Two+ showers sideband\\n' + r'$\\nu_e$ preselection and N-showers contained >= 2' + '\\n' + r'$\\pi^0$ scaled by 0.759'\n",
    "\n",
    "VARIABLE, BINS, RANGE, XTIT = 'reco_e',22,(-0.05,2.15),r\"Reconstructed Energy [GeV]\"\n",
    "\n",
    "out = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=this_query,\n",
    "    kind=\"event_category\",\n",
    "    draw_sys=True,\n",
    "    detsys=detsys,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=int(BINS),\n",
    "    range=RANGE,\n",
    ")\n",
    "fig, ax1, ax2 = out[0:3]\n",
    "\n",
    "if no_leg:\n",
    "    ax1.legend().set_visible(False) \n",
    "else:\n",
    "    ax1.set_title(this_title, loc='left')\n",
    "    ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "# ax1.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "# save_path = this_folder+VARIABLE\n",
    "# if no_leg:\n",
    "#     save_path += '_noleg'\n",
    "#             fig.savefig(save_path + '.png', dpi=250)    \n",
    "#         fig.savefig(save_path + '.pdf')    \n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Np selection on the 2+ shower sideband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unblinding_far_sideband import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = False\n",
    "no_leg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "database_ylim = {}\n",
    "#for stage in [1, 3, 4, 6, 7, 8]:\n",
    "#for stage in [5, 9]:\n",
    "for stage in [6]:\n",
    "    this_folder = ls.plots_path+'PELEE_two_showers_sideband_unblinding/'\n",
    "    if no_data:\n",
    "        this_folder += 'dry_run/'\n",
    "    else:\n",
    "        this_folder += 'with_data/'\n",
    "    this_folder += 'stage_{}/'.format(stage) #_reweight_pi0e_k035\n",
    "    !mkdir -p $this_folder\n",
    "\n",
    "    this_query = stages_queries_two_plus_showers[stage]\n",
    "    this_title = 'Two+ showers sideband\\n' + r'$\\nu_e$ preselection and N-showers contained >= 2' + '\\n' + stages_titles_two_plus_showers[stage]\n",
    "\n",
    "    if no_data:\n",
    "        this_query += ' and bnbdata==0'\n",
    "\n",
    "    for plot_variable in plot_variables:\n",
    "        VARIABLE, BINS, RANGE, XTIT = plot_variable[0:4]\n",
    "        #if VARIABLE!='pi0energy': continue\n",
    "        print(VARIABLE, BINS, RANGE, XTIT)\n",
    "        fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "            VARIABLE,   \n",
    "            query=this_query,\n",
    "            kind=\"event_category\",\n",
    "            draw_sys=True,\n",
    "            stacksort=3,\n",
    "            title=XTIT,\n",
    "            bins=BINS,\n",
    "            range=RANGE,\n",
    "        )[0:3]\n",
    "\n",
    "        if len(plot_variable) == 6:\n",
    "            if plot_variable[5] is True:\n",
    "                ax1.set_yscale('log')\n",
    "        else:\n",
    "            ax1.set_ylim(0, ax1.get_ylim()[1]*1.6)\n",
    "\n",
    "        if no_leg:\n",
    "            ax1.legend().set_visible(False) \n",
    "        else:\n",
    "            ax1.set_title(this_title, loc='left')\n",
    "\n",
    "        #ax2.set_ylim(0.5, 1.5)\n",
    "\n",
    "        database_ylim[VARIABLE] = ax1.get_ylim()[1]\n",
    "        plt.tight_layout()\n",
    "        save_path = this_folder+VARIABLE\n",
    "        if len(plot_variable) >= 5:\n",
    "            save_path += ('_' + plot_variable[4])\n",
    "        if no_leg:\n",
    "            save_path += '_noleg'\n",
    "        fig.savefig(save_path + '.png', dpi=250)    \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
