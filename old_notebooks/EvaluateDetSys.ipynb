{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "import os\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%m%d%Y\")\n",
    "print(\"date and time:\",date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gauss(x,mu,sigma,A):\n",
    "    norm = A/(np.sqrt(2*np.pi)*sigma)\n",
    "    exp  = np.exp(-((x-mu)**2)/(2*sigma*sigma))\n",
    "    return norm * exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "#if USEBDT:\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "import pandas as pd\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data_run123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COVARIANCE(n_cv,n_var):\n",
    "    cov = np.empty([len(n_cv), len(n_cv)])\n",
    "    cov.fill(0)\n",
    "\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            cov[i][j] += (n_var[i] - n_cv[i])*(n_var[j] - n_cv[j])\n",
    "\n",
    "    frac_cov = np.empty([len(n_cv), len(n_cv)])\n",
    "    corr = np.empty([len(n_cv), len(n_cv)])\n",
    "\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            frac_cov[i][j] =  cov[i][j] / (n_cv[i] * n_cv[j])\n",
    "            corr[i][j] = cov[i][j] / np.sqrt(cov[i][i] * cov[j][j])\n",
    "    return cov,frac_cov,corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINVAR = [\"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_dedx_max\",\n",
    "            \"trkfit\",\"trkpid\",\n",
    "            \"subcluster\",\"shrmoliereavg\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\"]\n",
    "\n",
    "LABELS =  ['pi0','nonpi0']\n",
    "\n",
    "TRAINVARZP = ['shrmoliereavg','shr_score', \"trkfit\",\"subcluster\",\n",
    "              \"CosmicIPAll3D\",\"CosmicDirAll3D\",\n",
    "              'secondshower_Y_nhit','secondshower_Y_vtxdist','secondshower_Y_dot','anglediff_Y',\n",
    "              'secondshower_V_nhit','secondshower_V_vtxdist','secondshower_V_dot','anglediff_V',\n",
    "              'secondshower_U_nhit','secondshower_U_vtxdist','secondshower_U_dot','anglediff_U',\n",
    "              \"shr_tkfit_2cm_dedx_U\", \"shr_tkfit_2cm_dedx_V\", \"shr_tkfit_2cm_dedx_Y\",\n",
    "              \"shr_tkfit_gap10_dedx_U\", \"shr_tkfit_gap10_dedx_V\", \"shr_tkfit_gap10_dedx_Y\",\n",
    "              \"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\"]\n",
    "\n",
    "LABELSZP = ['bkg']\n",
    "\n",
    "def loadBDT(DF):\n",
    "\n",
    "    for label, bkg_query in zip(LABELS, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            DF[label+\"_score\"] = booster.predict(xgb.DMatrix(DF[TRAINVAR]),\n",
    "                                                 ntree_limit=booster.best_iteration)\n",
    "\n",
    "    for label, bkg_query in zip(LABELSZP, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi_vx.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            DF[label+\"_score\"] = booster.predict(xgb.DMatrix(DF[TRAINVARZP]),\n",
    "                                                 ntree_limit=booster.best_iteration)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadnuevars(df):\n",
    "    \n",
    "    INTERCEPT = 0.0\n",
    "    SLOPE = 0.83\n",
    "\n",
    "    #if (loadnues):\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])                                                                                                                       \n",
    "    df[\"ptOverP\"] = df[\"pt\"]/df[\"p\"]\n",
    "    df[\"phi1MinusPhi2\"] = df[\"shr_phi\"]-df[\"trk_phi\"]\n",
    "    df[\"theta1PlusTheta2\"] = df[\"shr_theta\"]+df[\"trk_theta\"]\n",
    "    df['cos_shr_theta'] = np.cos(df['shr_theta'])\n",
    "    df['cos_trk_theta'] = np.cos(df['trk_theta'])\n",
    "    df['shr_tkfit_nhits_tot'] = (df['shr_tkfit_nhits_Y']+df['shr_tkfit_nhits_U']+df['shr_tkfit_nhits_V'])                                                                                                                                                                                              \n",
    "    df['shr_tkfit_2cm_nhits_tot'] = (df['shr_tkfit_2cm_nhits_Y']+df['shr_tkfit_2cm_nhits_U']+df['shr_tkfit_2cm_nhits_V'])                                                                                                                                                              \n",
    "    df['shr_tkfit_gap10_nhits_tot'] = (df['shr_tkfit_gap10_nhits_Y']+df['shr_tkfit_gap10_nhits_U']+df['shr_tkfit_gap10_nhits_V'])                                                                                                                             \n",
    "    df.loc[:,'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_nhits_U']>df['shr_tkfit_nhits_Y']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_Y']) & (df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_U']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_V']\n",
    "    df.loc[:,'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_gap10_nhits_U']>df['shr_tkfit_gap10_nhits_Y']),'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_gap10_nhits_V']>df['shr_tkfit_gap10_nhits_Y']) & (df['shr_tkfit_gap10_nhits_V']>df['shr_tkfit_gap10_nhits_U']),'shr_tkfit_gap10_dedx_max'] = df['shr_tkfit_gap10_dedx_V']\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + df[\"trk_energy_tot\"]\n",
    "    df['electron_e'] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE\n",
    "    df['protonenergy_corr'] = df['protonenergy']+0.000620/df['protonenergy']-0.001792\n",
    "    df.loc[(df['protonenergy_corr']>9998.), 'protonenergy_corr'] = 0\n",
    "\n",
    "\n",
    "    loadBDT(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# which samples are considered for the variations\n",
    "process = \"nue\" #\"nue\" #numu #ccpi0 #ncpi0\n",
    "\n",
    "# which selection variables to load from the dataframes\n",
    "selvars = \"nue\" #numu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue variables\n",
    "\n",
    "if process == \"nue\":\n",
    "    #PATH = '/home/david/data/searchingfornues/v08_00_00_44/'\n",
    "    PATH = '/Users/cerati/Notebooks/PELEE/root_files/0702/detsyst/'\n",
    "    mcCV   = 'nue_CV.root'\n",
    "    mcLYD  = 'nue_LYDown.root'\n",
    "    mcLYR  = 'nue_LYRayleigh.root'\n",
    "    mcLYA  = 'nue_LYAttenuation.root'\n",
    "    mcX    = 'nue_ScaleX.root'\n",
    "    mcYZ   = 'nue_ScaleYZ.root'\n",
    "    mcAXZ  = 'nue_AngleXZ.root'\n",
    "    mcAYZ  = 'nue_AngleYZ.root'\n",
    "    mcSCE  = 'nue_SCE.root'\n",
    "    mcdEdX = 'nue_dEdX.root'\n",
    "    mcR2 = 'nue_R2.root'\n",
    "    \n",
    "if process == \"numu\" or process == \"mc\":\n",
    "    PATH = '/Users/cerati/Notebooks/PELEE/root_files/0702/detsyst/'\n",
    "    mcCV   = 'prodgenie_bnb_nu_overlay_DetVar_CV_reco2_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcLYD  = 'prodgenie_bnb_nu_overlay_DetVar_LYDown_v08_00_00_37_v2_run3b_reco2_reco2.root'\n",
    "    mcLYR  = 'prodgenie_bnb_nu_overlay_DetVar_LYRayleigh_v08_00_00_37_run3b_reco2_reco2.root'\n",
    "    mcLYA  = 'prodgenie_bnb_nu_overlay_DetVar_LYAttenuation_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcX    = 'prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaleX_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcYZ   = 'prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaleYZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcAXZ  = 'prodgenie_bnb_nu_overlay_DetVar_WireModAngleXZ_v08_00_00_38_exe_run3b_reco2_reco2.root'\n",
    "    mcAYZ  = 'prodgenie_bnb_nu_overlay_DetVar_WireModAngleYZ_v08_00_00_38_exe_run3b_reco2_reco2.root'\n",
    "    mcSCE  = 'prodgenie_bnb_nu_overlay_DetVar_SCE_reco2_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcdEdX = 'prodgenie_bnb_nu_overlay_DetVar_wiremod_ScaledEdX_v08_00_00_39_run3b_reco2_reco2.root'\n",
    "    \n",
    "    \n",
    "if process == \"ccpi0\":\n",
    "    PATH = '/Users/cerati/Notebooks/PELEE/root_files/0702/detsyst/'\n",
    "    mcCV   = 'prodgenie_cc_pi0_overlay_DetVar_CV_reco2_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcLYD  = 'prodgenie_cc_pi0_overlay_DetVar_LYDown_v08_00_00_37_run3b_reco2_reco2.root'\n",
    "    mcLYR  = 'prodgenie_cc_pi0_overlay_DetVar_LYReyleigh_v08_00_00_37_run3b_reco2_reco2.root'\n",
    "    mcLYA  = ''\n",
    "    mcX    = 'prodgenie_cc_pi0_overlay_DetVar_wiremod_ScaleX_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcYZ   = 'prodgenie_cc_pi0_overlay_DetVar_wiremod_ScaleYZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcAXZ  = 'prodgenie_data_cc_pi0_overlay_DetVar_WireModAngleXZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcAYZ  = 'prodgenie_data_cc_pi0_overlay_DetVar_WireModAngleYZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcSCE  = 'prodgenie_cc_pi0_overlay_DetVar_SCE_reco2_v08_00_00_39_run3b_reco2_reco2.root'\n",
    "    mcdEdX = 'prodgenie_cc_pi0_overlay_DetVar_wiremod_ScaledEdX_v08_00_00_39_run3b_reco2_reco2.root'\n",
    "\n",
    "if process == \"ncpi0\":\n",
    "    PATH = '/Users/cerati/Notebooks/PELEE/root_files/0702/detsyst/'\n",
    "    mcCV   = 'prodgenie_nc_pi0_overlay_DetVar_CV_reco2_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcLYD  = 'prodgenie_nc_pi0_overlay_DetVar_LYDown_v08_00_00_37_run3b_reco2_reco2.root'\n",
    "    mcLYR  = 'prodgenie_nc_pi0_overlay_DetVar_LYReyliegh_v08_00_00_37_run3b_reco2_reco2.root'\n",
    "    mcLYA  = ''\n",
    "    mcX    = 'prodgenie_nc_pi0_overlay_DetVar_wiremod_ScaleX_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcYZ   = 'prodgenie_nc_pi0_overlay_DetVar_wiremod_ScaleYZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcAXZ  = ''\n",
    "    mcAYZ  = 'prodgenie_nc_pi0_overlay_DetVar_WireModAngleYZ_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcSCE  = 'prodgenie_nc_pi0_overlay_DetVar_SCE_reco2_v08_00_00_38_run3b_reco2_reco2.root'\n",
    "    mcdEdX = 'prodgenie_nc_pi0_overlay_DetVar_wiremod_ScaledEdX_v08_00_00_39_run3b_reco2_reco2.root'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DETVAR_N_V = [\"X\", \"YZ\", 'aYZ', \"aXZ\"]#,\"dEdX\",\"SCE\",\"LYD\",\"LYR\",\"LYA\"]\n",
    "#DETVAR_S_V = [mcX,mcYZ,mcAYZ,mcAXZ]#,nuedEdX,nueSCE,nueLYD,nueLYR,nueLYA]\n",
    "\n",
    "#DETVAR_N_V = [\"dEdX\",\"SCE\"]\n",
    "#DETVAR_S_V = [mcdEdX,mcSCE]\n",
    "\n",
    "#DETVAR_N_V = [\"LYD\",\"LYR\",\"LYA\"]\n",
    "#DETVAR_S_V = [mcLYD,mcLYR,mcLYA]\n",
    "\n",
    "#DETVAR_N_V = [\"X\", \"YZ\", 'aYZ', \"aXZ\",\"dEdX\",\"SCE\",\"LYD\",\"LYR\",\"LYA\"]\n",
    "#DETVAR_S_V = [mcX,mcYZ,mcAYZ,mcAXZ,mcdEdX,mcSCE,mcLYD,mcLYR,mcLYA]\n",
    "\n",
    "#DETVAR_N_V = [\"X\", \"YZ\", 'aYZ',\"dEdX\",\"SCE\",\"LYD\",\"LYR\"] #, \"aXZ\",\"LYA\"\n",
    "#DETVAR_S_V = [mcX,mcYZ,mcAYZ,mcdEdX,mcSCE,mcLYD,mcLYR] #,mcAXZ,mcLYA\n",
    "\n",
    "DETVAR_N_V = [\"X\", \"YZ\", 'aYZ',\"R2\",\"SCE\",\"LYD\",\"LYR\",\"aXZ\",\"LYA\"]\n",
    "DETVAR_S_V = [mcX,mcYZ,mcAYZ,mcR2,mcSCE,mcLYD,mcLYR,mcAXZ,mcLYA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'nuselection'\n",
    "tree = 'NeutrinoSelectionFilter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARDICT = load_data_run123.get_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (selvars == \"nue\"):\n",
    "    variables = VARDICT['VARIABLES'] + VARDICT['WEIGHTS'] + VARDICT['NUEVARS'] #+ load_data_run123.RCVRYVARS\n",
    "if (selvars == \"numu\"):\n",
    "    variables = VARDICT['VARIABLES'] + VARDICT['WEIGHTS'] + VARDICT['CRTVARS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Central Value DF\n",
    "CV = uproot.open(PATH+mcCV)[fold][tree]\n",
    "CVDF  = CV.pandas.df(variables, flatten=False)\n",
    "\n",
    "if (selvars == \"nue\"):\n",
    "    load_data_run123.process_uproot(CV,CVDF)\n",
    "    loadnuevars(CVDF)\n",
    "if (selvars == \"numu\"):\n",
    "    load_data_run123.process_uproot_numu(CV,CVDF)\n",
    "\n",
    "CVDF['bnbdata']  = np.zeros_like(CVDF['nslice'])\n",
    "CVDF['extdata']  = np.zeros_like(CVDF['nslice'])\n",
    "\n",
    "\n",
    "CVDF['identifier'] = CVDF['run']*100000 + CVDF['evt']  + ((100.*CVDF['nu_e']).astype(int))/1000. #to line up events with sample events\n",
    "\n",
    "NCV = CVDF.shape[0]\n",
    "\n",
    "print ('there are %i CV events'%(CVDF.shape[0]))\n",
    "\n",
    "DETSYS_SAMPLE_V = [] #list of merged CV-VAR dfataframes\n",
    "POT_V = [] #POT of samples? Not really used elsewhere\n",
    "\n",
    "for i,N in enumerate(DETVAR_N_V):\n",
    "    \n",
    "    VAR = uproot.open(PATH+DETVAR_S_V[i])[fold][tree]\n",
    "    VARDF = VAR.pandas.df(variables, flatten=False)\n",
    "    \n",
    "    VARDF['bnbdata']  = np.zeros_like(VARDF['nslice'])\n",
    "    VARDF['extdata']  = np.zeros_like(VARDF['nslice'])\n",
    "\n",
    "    \n",
    "    if (selvars == \"nue\"):\n",
    "        load_data_run123.process_uproot(VAR,VARDF)\n",
    "        loadnuevars(VARDF)\n",
    "    if (selvars == \"numu\"):\n",
    "        load_data_run123.process_uproot_numu(VAR,VARDF)\n",
    "\n",
    "    VARDF['identifier'] = VARDF['run']*100000 + VARDF['evt']  + ((100.*VARDF['nu_e']).astype(int))/1000.     \n",
    "    INT = pd.merge(CVDF, VARDF, how='inner', on=['identifier'],suffixes=('_CV', '_VAR'))\n",
    "\n",
    "    print ('intersection for %15s variation has %i events'%(DETVAR_N_V[i],INT.shape[0]))\n",
    "    DETSYS_SAMPLE_V.append(INT)\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETSYS_SAMPLE_V[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _selection(variable, sample, query=\"selected==1\"):#, extra_cut='',verbose=False):\n",
    "    \"\"\"\n",
    "    variable: string, about which info to be returned\n",
    "    sample: dataframe, to be queried\n",
    "    query: string, event-level queries\n",
    "    extra_cut: string, just another cut in addition to query\n",
    "    select_longest: bool, will select longest track in each slice after cuts\n",
    "        should be on when variable is track-level\n",
    "    fix: string, should be \"_CV\" or \"_VAR\"\n",
    "        on which sample to apply the cuts\n",
    "    return_fix: string, should be \"_CV\" or \"_VAR\"\n",
    "        which sample to return\n",
    "    \n",
    "    Returns an array of track/event variables that pass cuts\n",
    "    \"\"\"\n",
    "        \n",
    "    df = sample.copy().query(query)\n",
    "    #start dealing with the track variables\n",
    "    VARS = df[variable]#VARS is not clean of empty frames\n",
    "    \n",
    "    return VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "import unblinding_far_sideband\n",
    "importlib.reload(unblinding_far_sideband)\n",
    "\n",
    "import detsysselections\n",
    "importlib.reload(detsysselections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (selvars == \"nue\"):\n",
    "\n",
    "    sdb_key = 'None'\n",
    "    pre_key = 'NP'\n",
    "    sel_key = 'NPBDT'\n",
    "    QUERY_CV  = detsysselections.BDTCQ(\"CV\")\n",
    "    QUERY_VAR = detsysselections.BDTCQ(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'None'\n",
    "    #pre_key = 'ZP'\n",
    "    #sel_key = 'ZPBDT'\n",
    "    #QUERY_CV  = detsysselections.ZPBDTCQ(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.ZPBDTCQ(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'None'\n",
    "    #pre_key = 'NP'\n",
    "    #sel_key = 'NPXSBDT'\n",
    "    #QUERY_CV  = detsysselections.NPBDTXSQ(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.NPBDTXSQ(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'None'\n",
    "    #pre_key = 'NUE'\n",
    "    #sel_key = 'XPXSBDT'\n",
    "    #QUERY_CV  = detsysselections.XPBDTXSQ(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.XPBDTXSQ(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'None'\n",
    "    #pre_key = 'ZP'\n",
    "    #sel_key = 'ZPXSBDT'\n",
    "    #QUERY_CV  = detsysselections.ZPBDTXSQ(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.ZPBDTXSQ(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'TwoPShr'\n",
    "    #pre_key = 'NP'\n",
    "    #sel_key = 'None'\n",
    "    #QUERY_CV  = detsysselections.NPPRESQ_2pshowers(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.NPPRESQ_2pshowers(\"VAR\")\n",
    "\n",
    "    #sdb_key = 'TwoPShr'\n",
    "    #pre_key = 'ZP'\n",
    "    #sel_key = 'ZPLOOSETWOSHR'\n",
    "    #QUERY_CV  = detsysselections.ZPLCUTQ_2pshowers(\"CV\")\n",
    "    #QUERY_VAR = detsysselections.ZPLCUTQ_2pshowers(\"VAR\")\n",
    "    \n",
    "if (selvars == \"numu\"):\n",
    "    \n",
    "    sdb_key = 'None'\n",
    "    pre_key = 'NUMU'\n",
    "    sel_key = 'NUMU'\n",
    "\n",
    "    QUERY_CV  = detsysselections.NUMUPRESEL(\"CV\")\n",
    "    QUERY_VAR = detsysselections.NUMUPRESEL(\"VAR\")\n",
    "    \n",
    "    \n",
    "sideband = unblinding_far_sideband.sideband_categories[sdb_key]\n",
    "preselection = unblinding_far_sideband.preselection_categories[pre_key]\n",
    "sel =  unblinding_far_sideband.selection_categories[sel_key]\n",
    "\n",
    "SAVEPATH = ls.ntuple_path+'/detsys/'+'{}_{}_{}/'.format(sideband['dir'], preselection['dir'], sel['dir'])\n",
    "\n",
    "if not os.path.exists(SAVEPATH):\n",
    "    os.makedirs(SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEFIG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (selvars == \"nue\"):\n",
    "    plot_variables  = unblinding_far_sideband.kinematic_variables\n",
    "    plot_variables += unblinding_far_sideband.energy_variables\n",
    "    plot_variables += unblinding_far_sideband.bdt_common_variables_1eNp\n",
    "    plot_variables += unblinding_far_sideband.bdt_1enp_variables\n",
    "    plot_variables = [['reco_e',7,(0.05, 2.85),r\"Reconstructed Energy [GeV]\"]]\n",
    "    plot_variables = [['trkpid',10,(-1,1),\"track LLR PID\"]]\n",
    "    plot_variables = [['reco_e',14,(0.15, 1.55),r\"reco energy\"]]\n",
    "    plot_variables = [['reco_e',7,(0.1, 1.5),r\"reco energy\"]]\n",
    "    plot_variables = [['reco_e',10,(0.15, 1.55),r\"reco energy\"]]\n",
    "    #plot_variables = [['cos_trk_theta',6,(-1,1),r\"Leading Proton cos($\\theta$)\"]]\n",
    "    #plot_variables = [['cos_trk_theta',np.array([-1.,0.,0.4,0.7,1]),None,r\"Reconstructed Proton $\\cos\\left(\\theta\\right)$\"]]\n",
    "    #plot_variables = [['cos_shr_theta',np.array([-1.,0.2,0.7,0.9,1]),None,r\"Reconstructed Electron $\\cos\\left(\\theta\\right)$\"]]\n",
    "    #plot_variables = [['protonenergy',np.array([0,0.05,0.1,0.2,0.3,0.8]),None,r\"Reconstructed leading proton energy\"]]\n",
    "    #plot_variables = [['protonenergy_corr',np.array([0.,0.05,0.1,0.2,0.3,0.8]),None,r\"Reconstructed leading proton energy [GeV]\"]]\n",
    "    #plot_variables = [['electron_e',np.array([0.,0.4,0.9,1.5,4.5]),None,r\"Electron Energy [GeV]\"]]\n",
    "    #plot_variables = [['tksh_angle',10,(-1,1),r\"cos($\\Omega_{e,p}$)\"]]\n",
    "    #plot_variables = [['n_tracks_tot',1,(-0.5,0.5),r\"number of track\"]]\n",
    "    #plot_variables = [['tksh_distance',10,(0,10.0),\"Conversion distance [cm]\"]]\n",
    "    #plot_variables = [['n_protons_attach',4,(0.5, 4.5),\"Number of Protons At Vertex\"]]\n",
    "if (selvars == \"numu\"):\n",
    "    #plot_variables  = unblinding_far_sideband.numupresel_variables\n",
    "    plot_variables = unblinding_far_sideband.numusel_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(ls)\n",
    "\n",
    "#choose what you want to show\n",
    "#VARIABLE = 'reco_e'\n",
    "#TITLE = r'reconstructed neutrino energy [GeV]'\n",
    "#BINEDGES = np.linspace(0.15,1.55,15)\n",
    "\n",
    "#print (BINEDGES)\n",
    "#print(QUERY_CV)\n",
    "\n",
    "df_Err = []\n",
    "\n",
    "for VARIABLE,NBINS,RANGE,TITLE in plot_variables:\n",
    "\n",
    "    print(VARIABLE,NBINS,RANGE,TITLE)\n",
    "    \n",
    "    if RANGE is None:\n",
    "        BINEDGES = NBINS\n",
    "    else :\n",
    "        BINEDGES = np.linspace(RANGE[0],RANGE[1],NBINS+1)\n",
    "\n",
    "    #output errors\n",
    "    ERROR_OUT_V = []\n",
    "    QUAD_ERROR_V = np.zeros(len(BINEDGES)-1)\n",
    "\n",
    "    #fig = plt.figure(figsize=(20,3*len(DETVAR_N_V)))\n",
    "\n",
    "    index_labels = []\n",
    "    for b,bin_edge in enumerate(BINEDGES[:-1]):\n",
    "        index_labels.append(\"{}-{}\".format(round(bin_edge,2),round(BINEDGES[b+1],2)))   \n",
    "    df_error = pd.DataFrame(index=index_labels) \n",
    "\n",
    "    for idx,df_perm in enumerate(DETSYS_SAMPLE_V):\n",
    "        df = df_perm.copy()\n",
    "        print(\"starting {}...\".format(DETVAR_N_V[idx]))\n",
    "\n",
    "        VARS_CV = _selection(VARIABLE+'_CV',df,QUERY_CV)\n",
    "\n",
    "        VARS_VAR = _selection(VARIABLE+'_VAR',df,QUERY_VAR)\n",
    "\n",
    "        #######################################\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "        axis = fig.add_subplot(gs[0, 0])    \n",
    "        ################################\n",
    "        # CV-VAR histogram comparison\n",
    "        #get queried arrays of the variable\n",
    "        #get number of entries in each bin for each sample. and plot hists\n",
    "        n_cv, bins, p = axis.hist(VARS_CV ,bins=BINEDGES,histtype='step',\\\n",
    "                                  lw=2,color='k',label='CV')\n",
    "        n_var, bins, p = axis.hist(VARS_VAR,bins=BINEDGES,histtype='step',\\\n",
    "                                   lw=2,color='r',label='var : %s'%DETVAR_N_V[idx])\n",
    "\n",
    "        print ('n CV  : ',n_cv)\n",
    "        print ('n VAR : ',n_var)\n",
    "\n",
    "        bc = 0.5*(bins[1:]+bins[:-1]) #bin centers\n",
    "\n",
    "        cov,frac_cov,corr = COVARIANCE(n_cv,n_var) #calculate various matrices\n",
    "        error = np.sqrt(np.diag(frac_cov)) #systematic error is this\n",
    "        \n",
    "        df_error[DETVAR_N_V[idx]] = error\n",
    "\n",
    "        ERROR_OUT_V.append(error)\n",
    "        QUAD_ERROR_V += np.diag(frac_cov)\n",
    "        ##why Recomb is not added in quad_sum? \n",
    "        '''if (DETVAR_N_V[idx] != \"Recomb\"):\n",
    "            ERROR_OUT_V.append(error)\n",
    "            QUAD_ERROR_V += np.diag(frac_cov)'''\n",
    "\n",
    "        axis.set_xlabel(TITLE)\n",
    "        axis.set_ylabel('Num. Entries',fontsize=16)\n",
    "        #plt.ylim(0,plt.gca().get_ylim()[1]*1.5)\n",
    "        axis.legend(fontsize=15,loc=\"best\")\n",
    "        #plt.title(SAMPLE)\n",
    "\n",
    "        ########################################\n",
    "        axis = fig.add_subplot(gs[0, 1])\n",
    "        #####################################\n",
    "        # Fractional Covariance\n",
    "        #be consistent when comparing multiple plots\n",
    "        pos = axis.imshow(frac_cov, origin='lower', cmap='viridis',vmin=-0.025,vmax=0.025) \n",
    "        #print values onto the plot\n",
    "        # Limits for the extent\n",
    "        x_start = 0\n",
    "        x_end = len(n_cv)#-1\n",
    "        y_start = 0\n",
    "        y_end = len(n_cv)#-1\n",
    "        size = len(n_cv)#-1\n",
    "        jump_x = (x_end - x_start) / (2.0 * size)\n",
    "        jump_y = (y_end - y_start) / (2.0 * size)\n",
    "        x_positions = np.linspace(start=x_start, stop=x_end, num=size, endpoint=False)\n",
    "        y_positions = np.linspace(start=y_start, stop=y_end, num=size, endpoint=False)\n",
    "        for x_index, x in enumerate(x_positions):\n",
    "            #for x_index, x in enumerate(x_positions):\n",
    "            ERR = frac_cov[x_index, x_index]\n",
    "            label = \"{:.1f}\".format(100.*np.sqrt(ERR))\n",
    "            text_x = x #+ jump_x\n",
    "            text_y = x #+ jump_y\n",
    "            if (100.*np.sqrt(ERR) > 8):\n",
    "                axis.text(text_x, text_y, label, color='black', ha='center', va='center',fontsize=8)\n",
    "            else:\n",
    "                axis.text(text_x, text_y, label, color='white', ha='center', va='center',fontsize=8)\n",
    "        fig.colorbar(pos, ax=axis)\n",
    "        axis.set_ylabel(\"Bin number\")\n",
    "        axis.set_xlabel(\"Bin number\")\n",
    "        axis.set_title(sel_key)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if (SAVEFIG):\n",
    "            fig.savefig(SAVEPATH+VARIABLE+\"_%s_%s.pdf\"%(process,DETVAR_N_V[idx]))\n",
    "\n",
    "            # diagonal errors\n",
    "            fout = open(SAVEPATH+VARIABLE+\"_%s_%s.txt\"%(process,DETVAR_N_V[idx]),'w')\n",
    "            for i,e in enumerate(error):\n",
    "                fout.write('%.02f - %.02f, %.03f \\n'%(BINEDGES[i],BINEDGES[i+1],e))\n",
    "            fout.close()\n",
    "            # covariance matrix\n",
    "            fout = open(SAVEPATH+VARIABLE+\"_%s_%s_cov.txt\"%(process,DETVAR_N_V[idx]),'w')\n",
    "            string = ''\n",
    "            for n in range(len(error)):\n",
    "                string += '%.02f-%.02f, '%(BINEDGES[n],BINEDGES[n+1])\n",
    "            string += '\\n'\n",
    "            fout.write(string)\n",
    "            for i in range(len(error)):\n",
    "                string = '%.02f-%.02f, '%(BINEDGES[i],BINEDGES[i+1])\n",
    "                for j in range(len(error)):\n",
    "                    string += '%.04f, '%frac_cov[i,j]\n",
    "                string += '\\n'\n",
    "                fout.write(string)\n",
    "            fout.close()\n",
    "\n",
    "\n",
    "    #SAVEFIG = False\n",
    "\n",
    "    #quadsum\n",
    "    samples = list(df_error.keys())\n",
    "    df_error['sum'] = np.sqrt((df_error[samples]**2).sum(axis=1))\n",
    "    df_Err.append(df_error)\n",
    "    \n",
    "    #print (\"output Error : \", ERROR_OUT_V)\n",
    "    #print (\"output Error2 : \", np.array(np.sqrt(QUAD_ERROR_V)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_BINS = plot_variables[0][1]\n",
    "xtitle = plot_variables[0][3]\n",
    "labels = ['WireMod X', 'WireMod Y,Z', r'WireMod $\\theta_{XZ}$', 'Recomb','SCE', 'LY down', 'LY Rayleigh', r'WireMod $\\theta_{YZ}$', 'LYA','total uncertainty' ]\n",
    "\n",
    "#****add 1st element of the column in the beginning again****\n",
    "fig, ax1 = plt.subplots(figsize=(10,8))\n",
    "for i,columns in enumerate(df_error):\n",
    "    if columns=='sum':\n",
    "        ax1.plot(ax_BINS, np.append(df_error[columns][0], df_error[columns]), drawstyle='steps-pre', label='total uncertainty',lw=2,color='k',linestyle='--')\n",
    "    else:\n",
    "        ax1.plot(ax_BINS, np.append(df_error[columns][0], df_error[columns]), drawstyle='steps-pre', label=labels[i])\n",
    "ax1.legend(loc=2,ncol=3,frameon=False) \n",
    "ax1.set_xlabel(xtitle)\n",
    "ax1.set_ylabel('Fractional Uncertatinty')\n",
    "#ax1.set_title(r'$\\pi_0$ selection')\n",
    "ax1.set_ylim(0,0.25)\n",
    "ax1.set_xlim(ax_BINS[0],ax_BINS[-1])\n",
    "#fig.savefig(\"/Users/cerati/Notebooks/PELEE/plots/xsec-nue-bnb/%s_detsyts_summary.pdf\"%(plot_variables[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
