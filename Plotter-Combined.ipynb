{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import localSettings as ls\n",
    "print(ls.main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1560556807118,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "6qsD0G-yYJ9K",
    "outputId": "5d52a3ec-50be-44fc-da44-3c0593e98bc6"
   },
   "outputs": [],
   "source": [
    "main_path = ls.main_path\n",
    "sys.path.append(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHRCALIBFACTOR = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING BDT?\n",
    "USEBDT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cale to MCC8 CV?\n",
    "MCC8WEIGHTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGqTJ5JgaDsx"
   },
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)\n",
    "import uproot\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import nue_booster \n",
    "importlib.reload(nue_booster)\n",
    "import awkward\n",
    "\n",
    "params = {\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large'\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_run123 import process_uproot as process_uproot\n",
    "from load_data_run123 import process_uproot_recoveryvars as process_uproot_recoveryvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwoCIaigYJ9N"
   },
   "outputs": [],
   "source": [
    "fold = ls.fold\n",
    "tree = \"NeutrinoSelectionFilter\"\n",
    "\n",
    "R3BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_G1_beam_good_reco2_1e19'\n",
    "R3EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_F_G_all_reco2'\n",
    "R3NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run3_reco2_G_reco2'\n",
    "R3NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run3_reco2_reco2'\n",
    "R3NCPI0  = 'prodgenie_nc_pi0_uboone_overlay_mcc9.1_v08_00_00_26_run3_G_reco2'\n",
    "R3CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run3_G_reco2'\n",
    "R3CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run3_reco2_reco2'\n",
    "R3CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run3_reco2_reco2'\n",
    "R3NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_new_run3_reco2_reco2'\n",
    "R3NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_New_run3_reco2_reco2'\n",
    "\n",
    "#ls.ntuple_path = \"/Users/cerati/Notebooks/PELEE/root_files/0218/\"\n",
    "\n",
    "ur3mc = uproot.open(ls.ntuple_path+ls.RUN3+R3NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccpi0 = uproot.open(ls.ntuple_path+ls.RUN3+R3CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nue = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3data = uproot.open(ls.ntuple_path+ls.RUN3+R3BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ext = uproot.open(ls.ntuple_path+ls.RUN3+R3EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3dirt = uproot.open(ls.ntuple_path+ls.RUN3+R3DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3lee = uproot.open(ls.ntuple_path+ls.RUN3+R3NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ccnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3cccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3ncnopi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur3nccpi = uproot.open(ls.ntuple_path+ls.RUN3+R3NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R2NU = \"prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run2_reco2_D1D2_reco2\"\n",
    "R2NUE = \"prodgenie_bnb_intrinsic_nue_overlay_run2_v08_00_00_35_run2a_reco2_reco2\"\n",
    "\n",
    "ur2mc = uproot.open(ls.ntuple_path+ls.RUN2+R2NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2nue = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur2lee = uproot.open(ls.ntuple_path+ls.RUN2+R2NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "R1BNB = 'data_bnb_mcc9.1_v08_00_00_25_reco2_C1_beam_good_reco2_5e19'\n",
    "#R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_all_reco2'\n",
    "R1EXT = 'data_extbnb_mcc9.1_v08_00_00_25_reco2_C_D_E_all_reco2' #Run1 + Run2\n",
    "R1NU  = 'prodgenie_bnb_nu_uboone_overlay_mcc9.1_v08_00_00_26_filter_run1_reco2_reco2'\n",
    "R1NUE = 'prodgenie_bnb_intrinsice_nue_uboone_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1DRT = 'prodgenie_bnb_dirt_overlay_mcc9.1_v08_00_00_26_run1_reco2_reco2'\n",
    "R1NCPI0  = 'prodgenie_nc_pi0_uboone_overlay-v08_00_00_26_run1_reco2_reco2'\n",
    "R1CCPI0  = 'prodgenie_cc_pi0_uboone_overlay_v08_00_00_26_run1_reco2'\n",
    "R1CCNOPI = 'prodgenie_CCmuNoPi_overlay_mcc9_v08_00_00_33_all_run1_reco2_reco2'\n",
    "R1CCCPI  = 'prodgenie_filter_CCmuCPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCNOPI = 'prodgenie_ncnopi_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "R1NCCPI  = 'prodgenie_NCcPiNoPi0_overlay_mcc9_v08_00_00_33_run1_reco2_reco2'\n",
    "    \n",
    "ur1mc = uproot.open(ls.ntuple_path+ls.RUN1+R1NU+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1NCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccpi0 = uproot.open(ls.ntuple_path+ls.RUN1+R1CCPI0+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nue = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1data = uproot.open(ls.ntuple_path+ls.RUN1+R1BNB+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ext = uproot.open(ls.ntuple_path+ls.RUN1+R1EXT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1dirt = uproot.open(ls.ntuple_path+ls.RUN1+R1DRT+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1lee = uproot.open(ls.ntuple_path+ls.RUN1+R1NUE+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ccnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1cccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1CCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1ncnopi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCNOPI+ls.APPEND+\".root\")[fold][tree]\n",
    "ur1nccpi = uproot.open(ls.ntuple_path+ls.RUN1+R1NCCPI+ls.APPEND+\".root\")[fold][tree]\n",
    "\n",
    "variables = [\n",
    "    \"nu_pdg\", \"slpdg\", \"trk_score_v\", \"backtracked_pdg\",\n",
    "    \"category\", \"ccnc\",\n",
    "    \"crtveto\",\"crthitpe\",\"_closestNuCosmicDist\",\n",
    "    \"NeutrinoEnergy0\",\"NeutrinoEnergy1\",\"NeutrinoEnergy2\",\n",
    "    \"run\",\"sub\",\"evt\",\n",
    "    \"CosmicIP\",\"CosmicDirAll3D\",\"CosmicIPAll3D\",\n",
    "    \"nu_flashmatch_score\",\"best_cosmic_flashmatch_score\",\"best_obviouscosmic_flashmatch_score\",\n",
    "    \"trk_llr_pid_score_v\", # trk-PID score\n",
    "    \"_opfilter_pe_beam\", \"_opfilter_pe_veto\", # did the event pass the common optical filter (for MC only)\n",
    "    \"reco_nu_vtx_sce_x\",\"reco_nu_vtx_sce_y\",\"reco_nu_vtx_sce_z\",\n",
    "    \"nproton\", \"nu_e\", \n",
    "    \"hits_u\", \"hits_v\", \"hits_y\", \n",
    "    \"nproton\", \"mc_pdg\", \"slnunhits\", \"slnhits\", \"true_e_visible\",\n",
    "    \"npi0\",\"npion\",\"pion_e\",\"muon_e\",\"pi0truth_elec_etot\",\n",
    "    \"pi0_e\", \"evnunhits\", \"nslice\", \"interaction\",\n",
    "    \"slclustfrac\", \"reco_nu_vtx_x\", \"reco_nu_vtx_y\", \"reco_nu_vtx_z\",\n",
    "    \"trk_sce_start_x_v\",\"trk_sce_start_y_v\",\"trk_sce_start_z_v\",\n",
    "    \"trk_sce_end_x_v\",\"trk_sce_end_y_v\",\"trk_sce_end_z_v\",\n",
    "    \"trk_start_x_v\",\"trk_start_z_v\",\"trk_start_z_v\",\n",
    "    \"topological_score\"\n",
    "]\n",
    "\n",
    "WEIGHTS = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "WEIGHTSLEE = [\"weightSpline\",\"weightTune\",\"weightSplineTimesTune\", \"leeweight\", \"weightsGenie\", \"weightsFlux\", \"weightsReint\"]\n",
    "MCFVARS = [\"mcf_nu_e\",\"mcf_lep_e\",\"mcf_actvol\",\"mcf_nmm\",\"mcf_nmp\",\"mcf_nem\",\"mcf_nep\",\"mcf_np0\",\"mcf_npp\",\n",
    "           \"mcf_npm\",\"mcf_mcshr_elec_etot\",\"mcf_pass_ccpi0\",\"mcf_pass_ncpi0\",\n",
    "           \"mcf_pass_ccnopi\",\"mcf_pass_ncnopi\",\"mcf_pass_cccpi\",\"mcf_pass_nccpi\"]\n",
    "NUEVARS = [\"shr_dedx_Y\", \"shr_bkt_pdg\", \"shr_theta\",\"shr_pfp_id_v\",\n",
    "           \"shr_tkfit_dedx_U\",\"shr_tkfit_dedx_V\",\"shr_tkfit_dedx_Y\",\n",
    "           \"shr_tkfit_gap10_dedx_U\",\"shr_tkfit_gap10_dedx_V\",\"shr_tkfit_gap10_dedx_Y\",\n",
    "           \"shr_tkfit_2cm_dedx_U\",\"shr_tkfit_2cm_dedx_V\",\"shr_tkfit_2cm_dedx_Y\",\n",
    "           \"shrmoliereavg\",\"shrmoliererms\",\n",
    "           \"shr_tkfit_npointsvalid\",\"shr_tkfit_npoints\", # fitted vs. all hits for shower\n",
    "           \"shrclusfrac0\",\"shrclusfrac1\",\"shrclusfrac2\", # track-fitted hits / all hits\n",
    "           \"trkshrhitdist2\", \"trkshrhitdist0\",\"trkshrhitdist1\", #distance between track and shower in 2D\n",
    "           \"shrsubclusters0\",\"shrsubclusters1\",\"shrsubclusters2\", # number of sub-clusters in shower\n",
    "           \"secondshower_U_nhit\",\"secondshower_U_vtxdist\",\"secondshower_U_dot\",\"secondshower_U_dir\",\"shrclusdir0\",\n",
    "           \"secondshower_V_nhit\",\"secondshower_V_vtxdist\",\"secondshower_V_dot\",\"secondshower_V_dir\",\"shrclusdir1\",\n",
    "           \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"secondshower_Y_dir\",\"shrclusdir2\",\n",
    "           \"shrMCSMom\",\"DeltaRMS2h\",\"shrPCA1CMed_5cm\",\"CylFrac2h_1cm\",\n",
    "           \"shr_hits_tot\", \"shr_hits_u_tot\", \"shr_hits_v_tot\", \"shr_hits_y_tot\",\n",
    "           \"shr_theta_v\",\"shr_phi_v\",\"shr_energy_y_v\",\n",
    "           \"shr_start_x_v\",\"shr_start_z_v\",\"shr_start_z_v\",\n",
    "           \"shr_tkfit_dedx_U\", \"shr_tkfit_dedx_V\", \"trk_bkt_pdg\",  \n",
    "           \"shr_energy\", \"shr_dedx_U\", \"shr_dedx_V\", \"shr_phi\", \"trk_phi\", \"trk_theta\",\n",
    "           \"n_showers_contained\", \"shr_distance\", \"trk_distance\",\n",
    "           \"matched_E\", \"shr_bkt_E\", \"trk_bkt_E\",\n",
    "           \"shr_tkfit_nhits_Y\",\"shr_tkfit_nhits_U\",\"shr_tkfit_nhits_V\",\n",
    "           \"shr_tkfit_2cm_nhits_Y\",\"shr_tkfit_2cm_nhits_U\",\"shr_tkfit_2cm_nhits_V\",\n",
    "           \"shr_tkfit_gap10_nhits_Y\",\"shr_tkfit_gap10_nhits_U\",\"shr_tkfit_gap10_nhits_V\",\n",
    "           \"trk_energy\", \"tksh_distance\", \"tksh_angle\",\"contained_fraction\",\n",
    "           \"shr_score\", \"trk_score\", \"trk_hits_tot\",\"trk_len\",\n",
    "           \"trk_hits_tot\", \"trk_hits_u_tot\", \"trk_hits_v_tot\", \"trk_hits_y_tot\",\n",
    "           \"shr_energy_tot_cali\", \"shr_dedx_Y_cali\", \"trk_energy_tot\",\"shr_id\",\n",
    "           \"hits_ratio\", \"n_tracks_contained\",\n",
    "           \"p\", \"pt\", \"selected\"\n",
    "]\n",
    "RCVRYVARS = [\"shr_energy_tot\", \"trk_energy_tot\",\n",
    "             \"trk_end_x_v\",\"trk_end_y_v\",\"trk_end_z_v\",\n",
    "             \"trk_phi_v\",\"trk_theta_v\",\"trk_len_v\",\"trk_id\",\n",
    "             \"shr_px\",\"shr_py\",\"shr_pz\",\"shr_start_x\",\"shr_start_y\",\"shr_start_z\",\"trk_hits_max\",\n",
    "             \"shr_tkfit_dedx_u_v\",\"shr_tkfit_dedx_v_v\",\"shr_tkfit_dedx_y_v\",\n",
    "             \"shr_tkfit_dedx_nhits_u_v\",\"shr_tkfit_dedx_nhits_v_v\",\"shr_tkfit_dedx_nhits_y_v\",\n",
    "             \"trk2shrhitdist2\",\"trk1trk2hitdist2\",\"shr1shr2moliereavg\",\"shr1trk1moliereavg\",\"shr1trk2moliereavg\",\n",
    "             \"trk2_id\",\"shr2_id\",\"trk_hits_2nd\",\"shr_hits_2nd\"\n",
    "]\n",
    "variables += NUEVARS\n",
    "variables += RCVRYVARS\n",
    "\n",
    "#make the list unique\n",
    "variables = list(set(variables))\n",
    "print(variables)\n",
    "\n",
    "variables.remove(\"_closestNuCosmicDist\")\n",
    "variables.remove(\"crtveto\")\n",
    "variables.remove(\"crthitpe\")\n",
    "\n",
    "r3nue = ur3nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3mc = ur3mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r3ncpi0 = ur3ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccpi0 = ur3ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ccnopi = ur3ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3cccpi = ur3cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3ncnopi = ur3ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3nccpi = ur3nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3data = ur3data.pandas.df(variables, flatten=False)\n",
    "r3ext = ur3ext.pandas.df(variables, flatten=False)\n",
    "r3dirt = ur3dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r3lee = ur3lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r3lee[\"is_signal\"] = r3lee[\"category\"] == 11\n",
    "r3data[\"is_signal\"] = r3data[\"category\"] == 11\n",
    "r3nue[\"is_signal\"] = r3nue[\"category\"] == 11\n",
    "r3mc[\"is_signal\"] = r3mc[\"category\"] == 11\n",
    "r3dirt[\"is_signal\"] = r3dirt[\"category\"] == 11\n",
    "r3ext[\"is_signal\"] = r3ext[\"category\"] == 11\n",
    "r3ncpi0[\"is_signal\"] = r3ncpi0[\"category\"] == 11\n",
    "r3ccpi0[\"is_signal\"] = r3ccpi0[\"category\"] == 11\n",
    "r3ccnopi[\"is_signal\"] = r3ccnopi[\"category\"] == 11\n",
    "r3cccpi[\"is_signal\"] = r3cccpi[\"category\"] == 11\n",
    "r3ncnopi[\"is_signal\"] = r3ncnopi[\"category\"] == 11\n",
    "r3nccpi[\"is_signal\"] = r3nccpi[\"category\"] == 11\n",
    "r3lee.loc[r3lee['category'] == 1, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 10, 'category'] = 111\n",
    "r3lee.loc[r3lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur3lee,ur3mc,ur3ncpi0,ur3ccpi0,ur3ccnopi,ur3cccpi,ur3ncnopi,ur3nccpi,ur3nue,ur3ext,ur3data,ur3dirt]\n",
    "df_v = [r3lee,r3mc,r3ncpi0,r3ccpi0,r3ccnopi,r3cccpi,r3ncnopi,r3nccpi,r3nue,r3ext,r3data,r3dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    process_uproot(up,df)\n",
    "    process_uproot_recoveryvars(up,df)\n",
    "\n",
    "if (USEBDT == True):\n",
    "    train_r3ccpi0, r3ccpi0 = train_test_split(r3ccpi0, test_size=0.5, random_state=1990)\n",
    "    \n",
    "r1nue = ur1nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1mc = ur1mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r1ncpi0 = ur1ncpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccpi0 = ur1ccpi0.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ccnopi = ur1ccnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1cccpi = ur1cccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1ncnopi = ur1ncnopi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1nccpi = ur1nccpi.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1data = ur1data.pandas.df(variables, flatten=False)\n",
    "r1ext = ur1ext.pandas.df(variables, flatten=False)\n",
    "r1dirt = ur1dirt.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r1lee = ur1lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r1lee[\"is_signal\"] = r1lee[\"category\"] == 11\n",
    "r1data[\"is_signal\"] = r1data[\"category\"] == 11\n",
    "r1nue[\"is_signal\"] = r1nue[\"category\"] == 11\n",
    "r1mc[\"is_signal\"] = r1mc[\"category\"] == 11\n",
    "r1dirt[\"is_signal\"] = r1dirt[\"category\"] == 11\n",
    "r1ext[\"is_signal\"] = r1ext[\"category\"] == 11\n",
    "r1ncpi0[\"is_signal\"] = r1ncpi0[\"category\"] == 11\n",
    "r1ccpi0[\"is_signal\"] = r1ccpi0[\"category\"] == 11\n",
    "r1ccnopi[\"is_signal\"] = r1ccnopi[\"category\"] == 11\n",
    "r1cccpi[\"is_signal\"] = r1cccpi[\"category\"] == 11\n",
    "r1ncnopi[\"is_signal\"] = r1ncnopi[\"category\"] == 11\n",
    "r1nccpi[\"is_signal\"] = r1nccpi[\"category\"] == 11\n",
    "r1lee.loc[r1lee['category'] == 1, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 10, 'category'] = 111\n",
    "r1lee.loc[r1lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur1lee,ur1mc,ur1ncpi0,ur1ccpi0,ur1ccnopi,ur1cccpi,ur1ncnopi,ur1nccpi,ur1nue,ur1ext,ur1data,ur1dirt]\n",
    "df_v = [r1lee,r1mc,r1ncpi0,r1ccpi0,r1ccnopi,r1cccpi,r1ncnopi,r1nccpi,r1nue,r1ext,r1data,r1dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    process_uproot(up,df)\n",
    "    process_uproot_recoveryvars(up,df)\n",
    "\n",
    "r2nue = ur2nue.pandas.df(variables + WEIGHTS, flatten=False)\n",
    "r2mc = ur2mc.pandas.df(variables + WEIGHTS + MCFVARS, flatten=False)\n",
    "r2lee = ur2lee.pandas.df(variables + WEIGHTSLEE, flatten=False)\n",
    "\n",
    "r2lee[\"is_signal\"] = r2lee[\"category\"] == 11\n",
    "r2nue[\"is_signal\"] = r2nue[\"category\"] == 11\n",
    "r2mc[\"is_signal\"] = r2mc[\"category\"] == 11\n",
    "r2lee.loc[r2lee['category'] == 1, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 10, 'category'] = 111\n",
    "r2lee.loc[r2lee['category'] == 11, 'category'] = 111\n",
    "\n",
    "uproot_v = [ur2lee,ur2mc,ur2nue]\n",
    "df_v = [r2lee,r2mc,r2nue]\n",
    "for i,df in enumerate(df_v):\n",
    "    up = uproot_v[i]\n",
    "    process_uproot(up,df)    \n",
    "    process_uproot_recoveryvars(up,df)    \n",
    "    \n",
    "nue = pd.concat([r1nue,r2nue,r3nue],ignore_index=True)\n",
    "#nue = pd.concat([r3nue,r1nue],ignore_index=True)\n",
    "mc = pd.concat([r3mc,r2mc,r1mc],ignore_index=True)\n",
    "#mc = pd.concat([r3mc,r1mc],ignore_index=True)\n",
    "ncpi0 = pd.concat([r3ncpi0,r1ncpi0],ignore_index=True)\n",
    "ccpi0 = pd.concat([r3ccpi0,r1ccpi0],ignore_index=True)\n",
    "ccnopi = pd.concat([r3ccnopi,r1ccnopi],ignore_index=True)\n",
    "cccpi = pd.concat([r3cccpi,r1cccpi],ignore_index=True)\n",
    "ncnopi = pd.concat([r3ncnopi,r1ncnopi],ignore_index=True)\n",
    "nccpi = pd.concat([r3nccpi,r1nccpi],ignore_index=True)\n",
    "data = pd.concat([r3data,r1data],ignore_index=True)\n",
    "ext = pd.concat([r3ext,r1ext],ignore_index=True)\n",
    "dirt = pd.concat([r3dirt,r1dirt],ignore_index=True)\n",
    "lee = pd.concat([r1lee,r2lee,r3lee],ignore_index=True)\n",
    "#lee = pd.concat([r3lee,r1lee],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    \n",
    "    df.loc[ df['weightTune'] <= 0, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] == np.inf, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightTune'] > 100, 'weightTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightTune']) == True, 'weightTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] <= 0, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] == np.inf, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ df['weightSplineTimesTune'] > 100, 'weightSplineTimesTune' ] = 1.\n",
    "    df.loc[ np.isnan(df['weightSplineTimesTune']) == True, 'weightSplineTimesTune' ] = 1.\n",
    "    #df['weightSpline']  = df['weightSpline']  * df['weightTune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust from MCC9 CV to MCC8 CV\n",
    "\n",
    "if (MCC8WEIGHTS == True):\n",
    "\n",
    "    # scaling for QE\n",
    "    CV_bins = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,5.0]\n",
    "    CV_scaling = [2.5,2.0,1.7,1.45,1.3,1.25,1.175,1.15,1.14,1.1]\n",
    "    # scaling for RES\n",
    "\n",
    "    mc.loc[ (mc['interaction'] == 10), 'weightSpline' ] = 2 * mc['weightSpline']\n",
    "    ncpi0.loc[ (ncpi0['interaction'] == 10), 'weightSpline' ] = 2 * ncpi0['weightSpline']\n",
    "    ccpi0.loc[ (ccpi0['interaction'] == 10), 'weightSpline' ] = 2 * ccpi0['weightSpline']\n",
    "    ccnopi.loc[ (ccnopi['interaction'] == 10), 'weightSpline' ] = 2 * ccnopi['weightSpline']\n",
    "    cccpi.loc[ (cccpi['interaction'] == 10), 'weightSpline' ] = 2 * cccpi['weightSpline']\n",
    "    ncnopi.loc[ (ncnopi['interaction'] == 10), 'weightSpline' ] = 2 * ncnopi['weightSpline']\n",
    "    nccpi.loc[ (nccpi['interaction'] == 10), 'weightSpline' ] = 2 * nccpi['weightSpline']\n",
    "    nue.loc[ (nue['interaction'] == 10), 'weightSpline' ] = 2 * nue['weightSpline']\n",
    "    lee.loc[ (lee['interaction'] == 10), 'weightSpline' ] = 2 * lee['weightSpline']\n",
    "    dirt.loc[ (dirt['interaction'] == 10), 'weightSpline' ] = 2 * dirt['weightSpline']\n",
    "\n",
    "    for i, CV_bin in enumerate(CV_bins):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        mc.loc[ (mc['nu_e'] > CV_bins[i-1]) & (mc['nu_e'] < CV_bins[i]) & (mc['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * mc['weightSpline']\n",
    "        nue.loc[ (nue['nu_e'] > CV_bins[i-1]) & (nue['nu_e'] < CV_bins[i]) & (nue['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nue['weightSpline']\n",
    "        ncpi0.loc[ (nc['nu_e'] > CV_bins[i-1]) & (ncpi0['nu_e'] < CV_bins[i]) & (ncpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncpi0['weightSpline']\n",
    "        ccpi0.loc[ (ccpi0['nu_e'] > CV_bins[i-1]) & (ccpi0['nu_e'] < CV_bins[i]) & (ccpi0['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccpi0['weightSpline']\n",
    "        ccnopi.loc[ (ccnopi['nu_e'] > CV_bins[i-1]) & (ccnopi['nu_e'] < CV_bins[i]) & (ccnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ccnopi['weightSpline']\n",
    "        cccpi.loc[ (cccpi['nu_e'] > CV_bins[i-1]) & (cccpi['nu_e'] < CV_bins[i]) & (cccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * cccpi['weightSpline']\n",
    "        ncnopi.loc[ (ncnopi['nu_e'] > CV_bins[i-1]) & (ncnopi['nu_e'] < CV_bins[i]) & (ncnopi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * ncnopi['weightSpline']\n",
    "        nccpi.loc[ (nccpi['nu_e'] > CV_bins[i-1]) & (nccpi['nu_e'] < CV_bins[i]) & (nccpi['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * nccpi['weightSpline']\n",
    "        lee.loc[ (lee['nu_e'] > CV_bins[i-1]) & (lee['nu_e'] < CV_bins[i]) & (lee['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * lee['weightSpline']\n",
    "        dirt.loc[ (dirt['nu_e'] > CV_bins[i-1]) & (dirt['nu_e'] < CV_bins[i]) & (dirt['interaction'] == 0), 'weightSpline' ] = CV_scaling[i-1] * dirt['weightSpline']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the LLR-PID value for the \"track candidate\" (proton for nue selection, muon for numu)\n",
    "# can be done for any variable\n",
    "# code from Giuseppe!\n",
    "\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#df_v = [lee,mc,nue,ext,data,dirt]\n",
    "\n",
    "for i,df in enumerate(df_v):\n",
    "    df['subcluster'] = df['shrsubclusters0'] + df['shrsubclusters1'] + df['shrsubclusters2']\n",
    "    df['trkfit'] = df['shr_tkfit_npointsvalid'] / df['shr_tkfit_npoints']\n",
    "    # and the 2d angle difference\n",
    "    df['anglediff_Y'] = np.abs(df['secondshower_Y_dir']-df['shrclusdir2'])\n",
    "    #df['anglediff_V'] = np.abs(df['secondshower_V_dir']-df['shrclusdir1'])\n",
    "    #df['anglediff_U'] = np.abs(df['secondshower_U_dir']-df['shrclusdir0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df['shr_tkfit_nhits_tot'] = (df['shr_tkfit_nhits_Y']+df['shr_tkfit_nhits_U']+df['shr_tkfit_nhits_V'])\n",
    "    df['shr_tkfit_dedx_avg'] = (df['shr_tkfit_nhits_Y']*df['shr_tkfit_dedx_Y'] + df['shr_tkfit_nhits_U']*df['shr_tkfit_dedx_U'] + df['shr_tkfit_nhits_V']*df['shr_tkfit_dedx_V'])/df['shr_tkfit_nhits_tot']\n",
    "    df['shr_tkfit_2cm_nhits_tot'] = (df['shr_tkfit_2cm_nhits_Y']+df['shr_tkfit_2cm_nhits_U']+df['shr_tkfit_2cm_nhits_V'])\n",
    "    df['shr_tkfit_2cm_dedx_avg'] = (df['shr_tkfit_2cm_nhits_Y']*df['shr_tkfit_2cm_dedx_Y'] + df['shr_tkfit_2cm_nhits_U']*df['shr_tkfit_2cm_dedx_U'] + df['shr_tkfit_2cm_nhits_V']*df['shr_tkfit_2cm_dedx_V'])/df['shr_tkfit_2cm_nhits_tot']\n",
    "    df['shr_tkfit_gap10_nhits_tot'] = (df['shr_tkfit_gap10_nhits_Y']+df['shr_tkfit_gap10_nhits_U']+df['shr_tkfit_gap10_nhits_V'])\n",
    "    df['shr_tkfit_gap10_dedx_avg'] = (df['shr_tkfit_gap10_nhits_Y']*df['shr_tkfit_gap10_dedx_Y'] + df['shr_tkfit_gap10_nhits_U']*df['shr_tkfit_gap10_dedx_U'] + df['shr_tkfit_gap10_nhits_V']*df['shr_tkfit_gap10_dedx_V'])/df['shr_tkfit_gap10_nhits_tot']\n",
    "    df.loc[:,'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_Y']\n",
    "    df.loc[(df['shr_tkfit_nhits_U']>df['shr_tkfit_nhits_Y']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_U']\n",
    "    df.loc[(df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_Y']) & (df['shr_tkfit_nhits_V']>df['shr_tkfit_nhits_U']),'shr_tkfit_dedx_max'] = df['shr_tkfit_dedx_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,df in enumerate(df_v):\n",
    "    #df.loc[df['secondshower_U_dot'].isna(),'secondshower_U_dot'] = 0.0\n",
    "    #df.loc[df['secondshower_V_dot'].isna(),'secondshower_V_dot'] = 0.0\n",
    "    df.loc[df['secondshower_Y_dot'].isna(),'secondshower_Y_dot'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INTERCEPT = 0.0\n",
    "SLOPE = 0.83\n",
    "\n",
    "# define some energy-related variables\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"reco_e\"] = (df[\"shr_energy_tot_cali\"] + INTERCEPT) / SLOPE + df[\"trk_energy_tot\"]\n",
    "    df[\"reco_e_qe\"] = 0.938*((df[\"shr_energy\"]+INTERCEPT)/SLOPE)/(0.938 - ((df[\"shr_energy\"]+INTERCEPT)/SLOPE)*(1-np.cos(df[\"shr_theta\"])))\n",
    "    df[\"reco_e_rqe\"] = df[\"reco_e_qe\"]/df[\"reco_e\"]\n",
    "\n",
    "# and a way to filter out data\n",
    "for i,df in enumerate(df_v):\n",
    "    df[\"bnbdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "    df[\"extdata\"] = np.zeros_like(df[\"shr_energy\"])\n",
    "data[\"bnbdata\"] = np.ones_like(data[\"shr_energy\"])\n",
    "ext[\"extdata\"] = np.ones_like(ext[\"shr_energy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid double-counting of events out of FV in the NC/CC pi0 samples\n",
    "# not needed anymore since we improved matching with filtered samples\n",
    "#ncpi0 = ncpi0.query('category != 5')\n",
    "#ccpi0 = ccpi0.query('category != 5')\n",
    "#ccnopi = ccnopi.query('category != 5')\n",
    "#nccpi = nccpi.query('category != 5')\n",
    "#ncnopi = ncnopi.query('category != 5')\n",
    "\n",
    "## avoid recycling unbiased ext events (i.e. selecting a slice with little nu content from these samples)\n",
    "ccnopi = ccnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "cccpi = cccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "ncnopi = ncnopi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "nccpi = nccpi.query('(nslice==0 | (slnunhits/slnhits)>0.1)')\n",
    "\n",
    "# add back the cosmic category, for background only\n",
    "df_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "for i,df in enumerate(df_v):\n",
    "    df.loc[(df['category']!=1)&(df['category']!=10)&(df['category']!=11)&(df['category']!=111)&(df['slnunhits']/df['slnhits']<0.2), 'category'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to be trained on\n",
    "TRAINVAR = [\"shr_score\",\"tksh_distance\",\"tksh_angle\",\n",
    "            \"shr_tkfit_dedx_max\",\n",
    "            \"trkfit\",\"trkpid\",\n",
    "            \"subcluster\",\"shrmoliereavg\",\n",
    "            \"trkshrhitdist2\",\"hits_ratio\",\n",
    "            \"secondshower_Y_nhit\",\"secondshower_Y_vtxdist\",\"secondshower_Y_dot\",\"anglediff_Y\",\n",
    "            \"CosmicIPAll3D\",\"CosmicDirAll3D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcI43ileYJ9P"
   },
   "outputs": [],
   "source": [
    "LABELS =  ['pi0','nonpi0']\n",
    "#LABELS =  [\"bkg\"]\n",
    "\n",
    "if (USEBDT == True):\n",
    "    for label, bkg_query in zip(LABELS, nue_booster.bkg_queries):\n",
    "        with open(ls.pickle_path+'booster_%s_0304_extnumi.pickle' % label, 'rb') as booster_file:\n",
    "            booster = pickle.load(booster_file)\n",
    "            mc[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(mc[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nue[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nue[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ext[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ext[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            data[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(data[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            dirt[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(dirt[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            lee[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(lee[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccpi0[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccpi0[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ccnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ccnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            cccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(cccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            ncnopi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(ncnopi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)\n",
    "            nccpi[label+\"_score\"] = booster.predict(\n",
    "                xgb.DMatrix(nccpi[TRAINVAR]),\n",
    "                ntree_limit=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbdt_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotter\n",
    "import importlib\n",
    "importlib.reload(plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pamv0W8YJ9R"
   },
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"mc\": mc,\n",
    "    \"nue\": nue,\n",
    "    \"data\": data,\n",
    "    \"ext\": ext,\n",
    "    \"dirt\": dirt,\n",
    "    \"ncpi0\": ncpi0,\n",
    "    \"ccpi0\": ccpi0,\n",
    "    \"ccnopi\": ccnopi,\n",
    "    \"cccpi\": cccpi,\n",
    "    \"ncnopi\": ncnopi,\n",
    "    \"nccpi\": nccpi,\n",
    "    \"lee\": lee\n",
    "}\n",
    "\n",
    "scaling = 69.0/5.48 #0702\n",
    "#scaling = 101.0/5.48 #0702\n",
    "#scaling = 125.0/5.48 #0702\n",
    "#scaling = 1\n",
    "\n",
    "SPLIT = 1.0\n",
    "if (USEBDT == True):\n",
    "    SPLIT = 1.48\n",
    "\n",
    "#''' 0702\n",
    "weights = {\n",
    "    \"mc\": 1.50e-02 * scaling,\n",
    "    \"ext\": 2.86e-02 * scaling,\n",
    "    \"nue\": 2.83e-04 * scaling,\n",
    "    \"lee\": 2.83e-04 * scaling,\n",
    "    \"dirt\": 8.56e-02 * scaling,\n",
    "    \"ncpi0\": 1.11e-02 * scaling,\n",
    "    \"ccpi0\": 5.57e-03 * SPLIT * scaling,\n",
    "    \"ncnopi\": 4.78e-03 * scaling,\n",
    "    \"nccpi\": 2.04e-03 * scaling,\n",
    "    \"ccnopi\": 4.84e-03 * scaling,\n",
    "    \"cccpi\": 4.88e-03 * scaling,\n",
    "}\n",
    "pot = 5.48e19*scaling\n",
    "#'''\n",
    "my_plotter = plotter.Plotter(samples, weights, pot=pot)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nue preselection\n",
    "PRESQ = 'nslice == 1'\n",
    "PRESQ += ' and selected == 1'\n",
    "PRESQ += ' and shr_energy_tot_cali > 0.07'\n",
    "PRESQ += ' and ( (_opfilter_pe_beam > 0 and _opfilter_pe_veto < 20) or bnbdata == 1 or extdata == 1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1eNp preselection\n",
    "NPPRESQ = PRESQ\n",
    "NPPRESQ += ' and n_tracks_contained > 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very loose box cuts\n",
    "NPVLCUTQ = NPPRESQ\n",
    "NPVLCUTQ += ' and CosmicIPAll3D > 10.'\n",
    "NPVLCUTQ += ' and trkpid < 0.25'\n",
    "NPVLCUTQ += ' and hits_ratio > 0.5'\n",
    "NPVLCUTQ += ' and trkfit < 0.90'\n",
    "NPVLCUTQ += ' and n_showers_contained == 1'\n",
    "NPVLCUTQ += ' and tksh_distance < 10.0'\n",
    "NPVLCUTQ += ' and tksh_angle > -0.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loose box cuts\n",
    "NPLCUTQ = NPPRESQ\n",
    "NPLCUTQ += ' and CosmicIPAll3D > 10.'\n",
    "NPLCUTQ += ' and trkpid < 0.02'\n",
    "NPLCUTQ += ' and hits_ratio > 0.50'\n",
    "NPLCUTQ += ' and shrmoliereavg < 9'\n",
    "NPLCUTQ += ' and subcluster > 4'\n",
    "NPLCUTQ += ' and trkfit < 0.65'\n",
    "NPLCUTQ += ' and n_showers_contained == 1'\n",
    "NPLCUTQ += ' and tksh_distance < 6.0'\n",
    "NPLCUTQ += ' and (shr_tkfit_nhits_tot > 1 and shr_tkfit_dedx_max > 0.5 and shr_tkfit_dedx_max < 5.5)'\n",
    "#NPLCUTQ += ' and secondshower_Y_nhit < 50'\n",
    "NPLCUTQ += ' and tksh_angle > -0.9'\n",
    "NPLCUTQ += ' and shr_trk_len < 300.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tight box cuts\n",
    "NPTCUTQ = NPLCUTQ\n",
    "NPTCUTQ += ' and CosmicIPAll3D > 30.'\n",
    "NPTCUTQ += ' and CosmicDirAll3D > -0.98 and CosmicDirAll3D < 0.98'\n",
    "NPTCUTQ += ' and trkpid < 0.02'\n",
    "NPTCUTQ += ' and hits_ratio > 0.65'\n",
    "NPTCUTQ += ' and shr_score < 0.25'\n",
    "NPTCUTQ += ' and shrmoliereavg > 2 and shrmoliereavg < 10'\n",
    "NPTCUTQ += ' and subcluster > 7'\n",
    "NPTCUTQ += ' and trkfit < 0.70'\n",
    "NPTCUTQ += ' and n_showers_contained == 1'\n",
    "NPTCUTQ += ' and tksh_distance < 4.0'\n",
    "NPTCUTQ += ' and trkshrhitdist2 < 1.5'\n",
    "NPTCUTQ += ' and (shr_tkfit_nhits_tot > 1 and shr_tkfit_dedx_max > 1.0 and shr_tkfit_dedx_max < 3.8)'\n",
    "NPTCUTQ += ' and (secondshower_Y_nhit<=8 or secondshower_Y_dot<=0.8 or anglediff_Y<=40 or secondshower_Y_vtxdist>=100)'\n",
    "#NPTCUTQ += ' and secondshower_Y_nhit < 30'\n",
    "NPTCUTQ += ' and tksh_angle > -0.9 and tksh_angle < 0.70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (dirt.shape)\n",
    "print ((nue.query(NPTCUTQ)).shape)\n",
    "print ((nue.query(NPTCUTQ+ ' and nproton == 1 and nu_e < 0.8')).shape)\n",
    "print ((nue.query(NPTCUTQ+ ' and nproton > 1 and nu_e < 0.8')).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDT cuts\n",
    "# 0304 extnumi, pi0 and nonpi0\n",
    "BDTCQ = NPLCUTQ\n",
    "BDTCQ += ' and pi0_score > 0.67 and nonpi0_score > 0.70'\n",
    "#BDTCQ += ' and is_shr2splt==0 and is_trk2srtshr==0 and is_trk1bad==0'#'\n",
    "#BDTCQ += ' and is_trk1bad==1'\n",
    "#BDTCQ += ' and is_shr2splt==1'\n",
    "#BDTCQ += ' and is_trk2srtshr==1'\n",
    "#BDTCQ += ' and is_trk1embd==1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actual selection\n",
    "QUERY = BDTCQ\n",
    "# in case you do not want to look at the data\n",
    "QUERY += ' and bnbdata==0'\n",
    "# in case you want to apply the CRT veto\n",
    "#if ISRUN3: QUERY += ' and (crtveto!=1) and (_closestNuCosmicDist > 20.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY += ' and reco_e > 1.05 and n_showers_contained == 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext.query(QUERY)[[\"run\",\"evt\",\"reco_e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thruth-cut on MC sample to avoid double counting with truth-filters (i.e. ccpi0, ncpi0, cccpi, ...)\n",
    "NU_Q = \"~(abs(nu_pdg) == 12 & ccnc == 0)\"\n",
    "NU_Q += \" & ~(mcf_np0==1 & mcf_nmp==0 & mcf_nmm==0 & mcf_nem==0 & mcf_nep==0)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccpi0==1)\"\n",
    "NU_Q += \" & ~(mcf_pass_ccnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_ncnopi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_cccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\"\n",
    "NU_Q += \" & ~(mcf_pass_nccpi==1 & (nslice==0 | (slnunhits/slnhits)>0.1))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output files based on selection\n",
    "#uproot_v = [lee,mc,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,nue,ext,data,dirt]\n",
    "#fname_v = [NUE,NU,NCPI0,CCPI0,CCNOPI,CCCPI,NCNOPI,NCCPI,NUE,EXT,BNB,DRT]\n",
    "\n",
    "fname_v = [R3BNB,R3EXT,R3NU,R3NUE,R3DRT,R3NCPI0,R3CCPI0,R3CCNOPI,R3CCCPI,R3NCNOPI,R3NCCPI,\\\n",
    "           R2NU,R2NUE,\\\n",
    "           R1BNB,R1EXT,R1NU,R1NUE,R1DRT,R1NCPI0,R1CCPI0,R1CCNOPI,R1CCCPI,R1NCNOPI,R1NCCPI]\n",
    "\n",
    "dfsave_v = [data,ext,mc,nue,dirt,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi,\\\n",
    "            mc,nue,\\\n",
    "           data,ext,mc,nue,dirt,ncpi0,ccpi0,ccnopi,cccpi,ncnopi,nccpi]\n",
    "\n",
    "\n",
    "\n",
    "for i,name in enumerate(fname_v):\n",
    "    \n",
    "    #if (i == 0):\n",
    "    #    continue # skip LEE event. This one will be done within SBNFit\n",
    "        \n",
    "    df = dfsave_v[i]\n",
    "    \n",
    "    RUNS = \"run3/\"\n",
    "    if (i > 10):\n",
    "        RUNS = \"run2/\"\n",
    "    if (i > 12):\n",
    "        RUNS = \"run1/\"\n",
    "    \n",
    "    #fout = open(ls.ntuple_path+RUNS+name+ls.APPEND+'.txt','w')\n",
    "    dfsel = df.query(QUERY)\n",
    "    if ( (i == 2) or (i == 11) or (i==15)):\n",
    "        dfsel = dfsel.query(NU_Q)\n",
    "    print ('file %s has %i selected entries'%(name,dfsel.shape[0]))\n",
    "    #for i,row in dfsel.iterrows():\n",
    "    #    run = row['run']\n",
    "    #    sub = row['sub']\n",
    "    #    evt = row['evt']\n",
    "    #    fout.write('%i %i %i \\n'%(run,sub,evt))\n",
    "    #fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1560557343774,
     "user": {
      "displayName": "Stefano Roberto Soleti",
      "photoUrl": "https://lh4.googleusercontent.com/-hfLpspJu4Q0/AAAAAAAAAAI/AAAAAAAABmA/2kE4rtj8paU/s64/photo.jpg",
      "userId": "10372352518008961760"
     },
     "user_tz": 240
    },
    "id": "b93hN-pGYJ9T",
    "outputId": "17e7c7ed-3f12-4b03-805c-6698f1617878",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VARIABLE, BINS, RANGE, XTIT = 'reco_e',14,(0.15,1.55),\"Reconstructed Energy [GeV]\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'nonpi0_score',5,(0.5,1.0),\"non-pi0 score\"\n",
    "#VARIABLE, BINS, RANGE, XTIT = 'pi0_mass_Y',20,(0,500),\"pi0 mass Y\"\n",
    "\n",
    "fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "    VARIABLE,   \n",
    "    query=QUERY,#+' and (nu_pdg == 12) and (category != 111)',\n",
    "    kind=\"event_category\",\n",
    "    #kind=\"interaction\",\n",
    "    #kind=\"sample\",\n",
    "    #kind='particle_pdg',\n",
    "    draw_sys=False,\n",
    "    detsys=None,\n",
    "    ratio=True,\n",
    "    stacksort=3,\n",
    "    title=XTIT,\n",
    "    bins=BINS,\n",
    "    range=RANGE,\n",
    ")[0:3]\n",
    "\n",
    "print(\"Profile likelihood: %.2f sigma @ 1.01e21 POT\" % my_plotter.significance_likelihood)\n",
    "print(\"s/sqrt(b): %.2f sigma @ 1.01e21 POT\" % my_plotter.significance)\n",
    "\n",
    "#ax1.set_ylim(0,12)\n",
    "\n",
    "#ax1.set_ylim(0,22)\n",
    "#ax1.set_yscale(\"log\")\n",
    "#ax1.set_ylim(0,230)\n",
    "#ax2.set_ylim(0.5,1.5)\n",
    "#fig.savefig(ls.plots_path+VARIABLE+\"_BoxCut_R1R2R3_IntMode.pdf\")\n",
    "#fig.savefig(ls.plots_path+VARIABLE+\"_BoxCut_R1R2R3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# studies showing agreement between data and MC stats (w/ confidence intervals) vs. cut value\n",
    "\n",
    "def GetNumEvents(VAR,EMIN,EMAX,QUERY,PI0WEIGHT=1.0):\n",
    "    TOT  = 0.\n",
    "    DATA = 0.\n",
    "    for key, sample in samples.items():\n",
    "        THISQUERY = QUERY\n",
    "        # calculate weight for sample\n",
    "        weight = 1\n",
    "        if (key != 'data'):\n",
    "            weight = weights[key]    \n",
    "        if (key == 'mc'):\n",
    "            THISQUERY += ' and %s'%NU_Q\n",
    "        # calculate bare entries\n",
    "        dfsub = sample.query(THISQUERY)\n",
    "        vals_v = dfsub[VAR].values\n",
    "        weights_v = np.ones(len(vals_v)) * weight\n",
    "        if ((key != 'data') and (key != 'ext')):\n",
    "            weights_v = dfsub['weightSplineTimesTune'].values * weight\n",
    "        # scale pi0s\n",
    "        if ( (key=='ncpi0') or (key=='ccpi0') ):\n",
    "            weights_v = dfsub['weightSplineTimesTune'].values * weight * PI0WEIGHT\n",
    "        v,be = np.histogram(vals_v,bins=np.array([EMIN,EMAX]),weights=weights_v)\n",
    "        #print ('binned values : ',v)\n",
    "        #print ('sample %s has %.02f entries'%(key,v[0]))\n",
    "        if (key == 'data'):\n",
    "            DATA += v[0]\n",
    "        else:\n",
    "            TOT += v[0]\n",
    "    print ('DATA : %.01f. EXPECTATION : %.01f'%(DATA,TOT))\n",
    "    # poisson interval\n",
    "    # 68%\n",
    "    range68 = poisson.interval(0.68,TOT)\n",
    "    range95 = poisson.interval(0.99,TOT)\n",
    "    #print ('range 68%% %.02f -- %.02f'%(range68[0],range68[1]))\n",
    "    #print ('range 95%% %.02f -- %.02f'%(range95[0],range95[1]))\n",
    "    return DATA,TOT,range68[0],range68[1],range95[0],range95[1]\n",
    "\n",
    "BDTCUT_V = np.concatenate((np.linspace(0,0.5,21),np.linspace(0.5,1.0,15)),axis=0)\n",
    "#BDTCU\n",
    "DATA_V = []\n",
    "EXP_V = []\n",
    "MIN68_V = []\n",
    "MAX68_V = []\n",
    "MIN95_V = []\n",
    "MAX95_V = []\n",
    "\n",
    "GetNumEvents('reco_e',0.05,0.85,NPPRESQ+' and pi0_score > 0.7 and category!=111 and n_showers_contained == 1')\n",
    "\n",
    "'''\n",
    "for BDTCUT in BDTCUT_V:\n",
    "    print ('BDT cut : %.02f'%BDTCUT)\n",
    "    Q = NPPRESQ+' and (category != 111) and pi0_score > %.02f and pi0_score < 1.0'%BDTCUT\n",
    "    d,e,m68,M68,m95,M95 = GetNumEvents('reco_e',0.05,0.85,Q,PI0WEIGHT=1.0)\n",
    "    DATA_V.append(d)\n",
    "    EXP_V.append(e)\n",
    "    MIN68_V.append(m68)\n",
    "    MAX68_V.append(M68)\n",
    "    MIN95_V.append(m95)\n",
    "    MAX95_V.append(M95)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(BDTCUT_V,DATA_V,color='r',lw=2,label='observation')\n",
    "plt.plot(BDTCUT_V,EXP_V,color='b',lw=2,label='expectation')\n",
    "plt.fill_between(BDTCUT_V,MIN68_V,MAX68_V,alpha=0.5,color='b',label='68% interval')\n",
    "plt.fill_between(BDTCUT_V,MIN95_V,MAX95_V,alpha=0.5,color='c',label='99% interval')\n",
    "plt.grid()\n",
    "plt.xlabel('non-$\\pi^0$ BDT score cut')\n",
    "plt.ylabel('surviving events [4.8e19 POT]')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=1,fontsize=14)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuesub = nue.query('reco_e > 0.15 and reco_e < 0.25 and interaction==10')\n",
    "\n",
    "nuesub.query(QUERY)[[\"run\",\"evt\",\"reco_e\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PQUERY = QUERY\n",
    "PQUERY += ' and reco_e > 0.15 and reco_e < 1.55'\n",
    "#PQUERY += ' and reco_e > 0.15 and reco_e < 0.75'\n",
    "#PQUERY += ' and shr_tkfit_dedx_Y < 0'\n",
    "plots = []\n",
    "plots.append(['tksh_distance',20,(0,10),\"tksh distance [cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_Y',20,(0,10),\"shr tkfit dE/dx (Y, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_U',20,(0,10),\"shr tkfit dE/dx (U, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_V',20,(0,10),\"shr tkfit dE/dx (V, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 0-4 cm) [MeV/cm]\"])\n",
    "plots.append(['shr_tkfit_dedx_max',20,(0,10),\"shr tkfit dE/dx (max, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 0-4 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_2cm_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 0-2 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_dedx_avg',20,(0,10),\"shr tkfit dE/dx (avg, 1-5 cm) [MeV/cm]\"])\n",
    "#plots.append(['shr_tkfit_gap10_nhits_tot',20,(0,20),\"shr tkfit nhits (tot, 1-5 cm) [MeV/cm]\"])\n",
    "plots.append(['tksh_angle',20,(-1,1),\"cos(tksh angle)\"])\n",
    "plots.append(['trkfit',20,(0,1),\"Fraction of Track-fitted points\"])\n",
    "plots.append(['shrmoliereavg',20,(0,50),\"average Moliere angle [degrees]\"])\n",
    "plots.append(['trkpid',15,(-1,1),\"track LLR PID\"])\n",
    "#plots.append(['n_showers_contained',10,(0,10),\"n showers contained\"])\n",
    "#plots.append(['n_tracks_contained',10,(0,10),\"n tracks contained\"])\n",
    "plots.append(['shr_score',20,(0,0.5),\"shr score\"])\n",
    "#plots.append(['trk_score',20,(0.5,1.0),\"trk score\"])\n",
    "plots.append(['hits_ratio',20,(0,1),\"shower hits/all hits\"])\n",
    "plots.append(['slclustfrac',20,(0,1),\"slice clustered fraction\"])\n",
    "plots.append(['CosmicIP',20,(0,200),\"Cosmic IP from vtx [cm]\"])\n",
    "#plots.append(['reco_nu_vtx_x',20,(0,260),\"x\"])\n",
    "#plots.append(['reco_nu_vtx_y',20,(-120,120),\"y\"])\n",
    "#plots.append(['reco_nu_vtx_z',20,(0,1100),\"z\"])\n",
    "#plots.append(['reco_e_rqe',20,(0,2),\"rqe\"])\n",
    "plots.append(['trkshrhitdist2',20,(0,10),\"2D trk-shr distance (Y)\"])\n",
    "plots.append(['subcluster',20,(0,20),\"N sub-clusters in shower\"])\n",
    "#plots.append(['shrmoliererms',20,(0,5000),\"RMS Moliere angle [degrees]\"])\n",
    "#plots.append(['shr_energy_tot_cali',20,(0,1),\"shr energy (calibrated) [GeV]\"])\n",
    "#plots.append(['contained_fraction',20,(0.,1),\"contained fraction\"])\n",
    "#plots.append(['hits_y',20,(0.,1000),\"N hits Y plane\"])\n",
    "#plots.append(['pi0_mass_Y',25,(-50.,200),\"pi0 mass [Mev]\"])\n",
    "#plots.append(['pi0_gammadot',20,(-1,1),\"2-shower angle\"])\n",
    "plots.append(['secondshower_Y_nhit',20,(0,200),\"Nhit 2nd shower (Y)\"])\n",
    "plots.append(['secondshower_Y_dot',20,(-1,1),\"cos(2nd shower direction wrt vtx) (Y)\"])\n",
    "plots.append(['anglediff_Y',20,(0,350),\"angle diff 1st-2nd shower (Y) [degrees]\"])\n",
    "plots.append(['secondshower_Y_vtxdist',20,(0.,200),\"vtx dist 2nd shower (Y)\"])\n",
    "#plots.append(['trackcaloenergy',15,(0,300),\"Track Calo Energy [Mev]\"])\n",
    "plots.append(['CosmicIPAll3D',20,(0,200),\"CosmicIPAll3D [cm]\"])\n",
    "plots.append(['CosmicDirAll3D',20,(-1,1),\"cos(CosmicDirAll3D)\"])\n",
    "if USEBDT:\n",
    "    #plots = []\n",
    "    #plots.append(['bkg_score',50,(0.5,1),\"all-bkg BDT response\"])\n",
    "    plots.append(['pi0_score',50,(0.5,1),\"$\\pi^0$ BDT response\"])\n",
    "    plots.append(['nonpi0_score',50,(0.5,1),\"non-$\\pi^0$ BDT response\"])\n",
    "    #plots.append(['cc_score',40,(0.,1),\"cc score\"])\n",
    "    #plots.append(['cosmic_score',40,(0.,1),\"cosmic score\"])\n",
    "    #plots.append(['ext_score',40,(0.,1),\"ext score\"])\n",
    "    #plots.append(['ccpi0_score',40,(0.,1),\"ccpi0 score\"])\n",
    "    #plots.append(['ncpi0_score',40,(0.,1),\"ncpi0 score\"])\n",
    "#plots = []\n",
    "#plots.append(['secondshower_Y_nhit',20,(0,100),\"Nhit 2nd shower (Y)\"])\n",
    "for VARIABLE, BINS, RANGE, XTIT in plots:\n",
    "    print(VARIABLE, BINS, RANGE, XTIT)\n",
    "    fig, ax1, ax2 = my_plotter.plot_variable(\n",
    "        VARIABLE,   \n",
    "        query=PQUERY,\n",
    "        kind=\"event_category\",\n",
    "        #kind=\"interaction\",\n",
    "        #kind=\"sample\",\n",
    "        draw_sys=False,\n",
    "        stacksort=3,\n",
    "        title=XTIT,\n",
    "        bins=BINS,\n",
    "        range=RANGE,\n",
    "    )[0:3]\n",
    "    ax1.set_ylim(0,ax1.get_ylim()[1]*1.4)\n",
    "    #ax1.set_yscale(\"log\")\n",
    "    fig.show()\n",
    "    #fig.savefig(ls.plots_path+\"0109/run1/presel/\"+VARIABLE+date_time+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY += ' and reco_e > 0.2 and reco_e < 0.8 and npi0==0 and ccnc==1'# and npion>0\n",
    "QUERY += \" and nu_pdg == 14\"\n",
    "#QUERY += \" and ~(pi0truth_elec_etot>=15 or muon_e<0.3)\"\n",
    "print(QUERY)\n",
    "mc.query(QUERY)[[\"run\",\"sub\",\"evt\",\"reco_e\",\"slnunhits\",\"slnhits\",\"ccnc\",\"nu_e\",\"npi0\",\"npion\",\"nproton\",\"proton_e\",\"nneutron\",\"muon_e\",\"pi0truth_elec_etot\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output files based on selection\n",
    "fname_v = [NUE,NU,PI0,NUE,EXT,BNB,DRT]\n",
    "\n",
    "for i,name in enumerate(fname_v):\n",
    "    if (i == 0):\n",
    "        continue # skip LEE event. This one will be done within SBNFit\n",
    "        \n",
    "    df = dfbdt_v[i]\n",
    "\n",
    "    fout = open(ls.ntuple_path+name+'.txt','w')\n",
    "    dfsel = df.query(QUERY)\n",
    "    print ('file %s has %i selected entries'%(name,dfsel.shape[0]))\n",
    "    for i,row in dfsel.iterrows():\n",
    "        run = row['run'].values[0]\n",
    "        sub = row['sub'].values[0]\n",
    "        evt = row['evt'].values[0]\n",
    "        fout.write('%i %i %i \\n'%(run,sub,evt))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BINS = np.linspace(0,1,25)\n",
    "VAR = 'cosmic_score'\n",
    "\n",
    "nueplot = nue.query(QUERY)\n",
    "nueplotecut = nueplot.query('nu_e < 0.8')\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist(nueplot[VAR].values,bins=BINS,histtype='step',lw=2,color='red',label='all nue')\n",
    "plt.hist(nueplotecut[VAR].values,bins=BINS,histtype='step',lw=2,color='m',label='nue < 0.8 GeV')\n",
    "#plt.hist(nue[VAR].values,bins=BINS,histtype='step',lw=2,color='green')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(VAR)\n",
    "plt.show()\n",
    "\n",
    "BINS2D = (np.linspace(0,3.0,25),BINS)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.hist2d(nueplot['nu_e'].values,nueplot[VAR].values,bins=BINS2D)\n",
    "#plt.hist(nue[VAR].values,bins=BINS,histtype='step',lw=2,color='green')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_range = (0.1,0.8)\n",
    "n_bins = 7\n",
    "\n",
    "n_tot = np.empty([50, n_bins])\n",
    "n_cv_tot = np.empty(n_bins)\n",
    "n_tot.fill(0)\n",
    "n_cv_tot.fill(0)\n",
    "score_cut = 0.997\n",
    "\n",
    "my_cmap = cm.get_cmap('viridis')\n",
    "\n",
    "for t in samples:\n",
    "    if t in [\"ext\", \"data\", \"lee\"]:\n",
    "        continue\n",
    "    tree = samples[t]\n",
    "    \n",
    "    extra_query = \"\"\n",
    "    if t == \"mc\":\n",
    "        extra_query = \"& ~(nu_pdg == 12 & ccnc == 0) & ~(npi0 != 0 & ccnc == 1)\"\n",
    "        \n",
    "    queried_tree = tree.query(\"selected==1 & global_score > %g %s & interaction == 1\" % (score_cut, extra_query))\n",
    "    variable = queried_tree[\"reco_e\"]\n",
    "    genie_weights = queried_tree[\"weightsGenie\"]\n",
    "    spline_fix = queried_tree[\"weightSpline\"]*weights[t]\n",
    "\n",
    "    s = genie_weights\n",
    "    df = pd.DataFrame(s.values.tolist())\n",
    "\n",
    "\n",
    "    n_cv, bins = np.histogram(\n",
    "        variable,\n",
    "        range=x_range,\n",
    "        bins=n_bins,\n",
    "        weights=spline_fix)\n",
    "    \n",
    "    n_cv_tot += n_cv\n",
    "\n",
    "    if not df.empty:\n",
    "        for i in range(50):\n",
    "            weight = df[i].values\n",
    "            weight[np.isnan(weight)] = 1\n",
    "            weight[weight > 100] = 1\n",
    "\n",
    "            n, bins = np.histogram(\n",
    "                variable, weights=weight*spline_fix, range=x_range, bins=n_bins)\n",
    "\n",
    "            n_tot[i] += n\n",
    "\n",
    "        \n",
    "bincenters = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "left,right = bins[:-1],bins[1:]\n",
    "X = np.array([left,right]).T.flatten()\n",
    "Y = np.array([n_cv_tot,n_cv_tot]).T.flatten()\n",
    "plt.plot(X,Y,color='r',linewidth=2,label='Central value')\n",
    "\n",
    "    \n",
    "cov = np.empty([len(n_cv), len(n_cv)])\n",
    "cov.fill(0)\n",
    "\n",
    "my_norm = Normalize(vmin=min((sum(n) for n in n_tot)), vmax=max((sum(n) for n in n_tot)))\n",
    "\n",
    "for n in n_tot:\n",
    "    left,right = bins[:-1],bins[1:]\n",
    "    X = np.array([left,right]).T.flatten()\n",
    "    Y = np.array([n,n]).T.flatten()\n",
    "    plt.plot(X,Y,color=my_cmap(my_norm(sum(n))),zorder=-32)\n",
    "    for i in range(len(n_cv)):\n",
    "        for j in range(len(n_cv)):\n",
    "            cov[i][j] += (n[i] - n_cv_tot[i]) * (n[j] - n_cv_tot[j])\n",
    "\n",
    "cov /= 50\n",
    "            \n",
    "frac_cov = np.empty([len(n_cv), len(n_cv)])\n",
    "corr = np.empty([len(n_cv), len(n_cv)])\n",
    "\n",
    "for i in range(len(n_cv)):\n",
    "    for j in range(len(n_cv)):\n",
    "        frac_cov[i][j] = cov[i][j] / (n_cv_tot[i] * n_cv_tot[j])\n",
    "        corr[i][j] = cov[i][j] / np.sqrt(cov[i][i] * cov[j][j])\n",
    "\n",
    "        \n",
    "plt.errorbar(\n",
    "    bincenters, \n",
    "    n_cv_tot,\n",
    "    yerr=np.sqrt(np.diag(cov)), \n",
    "    fmt='none', \n",
    "    ecolor='r',\n",
    "    linewidth=2,\n",
    "    label='GENIE sys. uncertainties')\n",
    "\n",
    "print(np.sqrt(np.diag(cov))/n_cv_tot)\n",
    "plt.xlim(x_range[0], x_range[1])\n",
    "plt.xlabel(r\"$E_{deposited}$ [GeV]\")\n",
    "plt.legend()\n",
    "plt.ylim(ymin=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/spec.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "pos = ax.imshow(frac_cov, origin='lower', cmap='viridis')\n",
    "ax.set_title(\"Fractional covariance matrix\")\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/frac.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "pos = ax.imshow(corr, origin='lower', cmap='inferno')\n",
    "ax.set_ylabel(\"Bin number\")\n",
    "ax.set_xlabel(\"Bin number\")\n",
    "fig.colorbar(pos)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/corr.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_plotter.plot_2d(\n",
    "    \"global_score\",\n",
    "    \"ncpi0_score\",\n",
    "    query=\"selected==1\",\n",
    "    bins_x=50,\n",
    "    bins_y=50,\n",
    "    range_x=(0., 1),\n",
    "    range_y=(0., 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Plotter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
